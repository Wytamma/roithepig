2025-05-13 12:50:22 Training with configuration:
2025-05-13 12:50:22 data:
2025-05-13 12:50:22   bbox_margin: 20
2025-05-13 12:50:22   colormode: RGB
2025-05-13 12:50:22   inference:
2025-05-13 12:50:22     normalize_images: True
2025-05-13 12:50:22   train:
2025-05-13 12:50:22     affine:
2025-05-13 12:50:22       p: 0.5
2025-05-13 12:50:22       rotation: 30
2025-05-13 12:50:22       scaling: [0.5, 1.25]
2025-05-13 12:50:22       translation: 0
2025-05-13 12:50:22     crop_sampling:
2025-05-13 12:50:22       width: 448
2025-05-13 12:50:22       height: 448
2025-05-13 12:50:22       max_shift: 0.1
2025-05-13 12:50:22       method: hybrid
2025-05-13 12:50:22     gaussian_noise: 12.75
2025-05-13 12:50:22     motion_blur: True
2025-05-13 12:50:22     normalize_images: True
2025-05-13 12:50:22 device: auto
2025-05-13 12:50:22 metadata:
2025-05-13 12:50:22   project_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12
2025-05-13 12:50:22   pose_config_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12/dlc-models-pytorch/iteration-0/pigs-heart-rateMay12-trainset95shuffle1/train/pytorch_config.yaml
2025-05-13 12:50:22   bodyparts: ['L ear base', 'R ear base', 'Mid snout']
2025-05-13 12:50:22   unique_bodyparts: []
2025-05-13 12:50:22   individuals: ['animal']
2025-05-13 12:50:22   with_identity: None
2025-05-13 12:50:22 method: bu
2025-05-13 12:50:22 model:
2025-05-13 12:50:22   backbone:
2025-05-13 12:50:22     type: ResNet
2025-05-13 12:50:22     model_name: resnet50_gn
2025-05-13 12:50:22     output_stride: 16
2025-05-13 12:50:22     freeze_bn_stats: False
2025-05-13 12:50:22     freeze_bn_weights: False
2025-05-13 12:50:22   backbone_output_channels: 2048
2025-05-13 12:50:22   heads:
2025-05-13 12:50:22     bodypart:
2025-05-13 12:50:22       type: HeatmapHead
2025-05-13 12:50:22       weight_init: normal
2025-05-13 12:50:22       predictor:
2025-05-13 12:50:22         type: HeatmapPredictor
2025-05-13 12:50:22         apply_sigmoid: False
2025-05-13 12:50:22         clip_scores: True
2025-05-13 12:50:22         location_refinement: True
2025-05-13 12:50:22         locref_std: 7.2801
2025-05-13 12:50:22       target_generator:
2025-05-13 12:50:22         type: HeatmapGaussianGenerator
2025-05-13 12:50:22         num_heatmaps: 3
2025-05-13 12:50:22         pos_dist_thresh: 17
2025-05-13 12:50:22         heatmap_mode: KEYPOINT
2025-05-13 12:50:22         gradient_masking: False
2025-05-13 12:50:22         generate_locref: True
2025-05-13 12:50:22         locref_std: 7.2801
2025-05-13 12:50:22       criterion:
2025-05-13 12:50:22         heatmap:
2025-05-13 12:50:22           type: WeightedMSECriterion
2025-05-13 12:50:22           weight: 1.0
2025-05-13 12:50:22         locref:
2025-05-13 12:50:22           type: WeightedHuberCriterion
2025-05-13 12:50:22           weight: 0.05
2025-05-13 12:50:22       heatmap_config:
2025-05-13 12:50:22         channels: [2048, 3]
2025-05-13 12:50:22         kernel_size: [3]
2025-05-13 12:50:22         strides: [2]
2025-05-13 12:50:22       locref_config:
2025-05-13 12:50:22         channels: [2048, 6]
2025-05-13 12:50:22         kernel_size: [3]
2025-05-13 12:50:22         strides: [2]
2025-05-13 12:50:22 net_type: resnet_50
2025-05-13 12:50:22 runner:
2025-05-13 12:50:22   type: PoseTrainingRunner
2025-05-13 12:50:22   gpus: None
2025-05-13 12:50:22   key_metric: test.mAP
2025-05-13 12:50:22   key_metric_asc: True
2025-05-13 12:50:22   eval_interval: 10
2025-05-13 12:50:22   optimizer:
2025-05-13 12:50:22     type: AdamW
2025-05-13 12:50:22     params:
2025-05-13 12:50:22       lr: 0.0005
2025-05-13 12:50:22   scheduler:
2025-05-13 12:50:22     type: LRListScheduler
2025-05-13 12:50:22     params:
2025-05-13 12:50:22       lr_list: [[0.0001], [1e-05]]
2025-05-13 12:50:22       milestones: [90, 120]
2025-05-13 12:50:22   snapshots:
2025-05-13 12:50:22     max_snapshots: 5
2025-05-13 12:50:22     save_epochs: 5
2025-05-13 12:50:22     save_optimizer_state: False
2025-05-13 12:50:22 train_settings:
2025-05-13 12:50:22   batch_size: 8
2025-05-13 12:50:22   dataloader_workers: 0
2025-05-13 12:50:22   dataloader_pin_memory: False
2025-05-13 12:50:22   display_iters: 500
2025-05-13 12:50:22   epochs: 200
2025-05-13 12:50:22   seed: 42
2025-05-13 12:50:22 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-05-13 12:50:23 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-05-13 12:50:24 Data Transforms:
2025-05-13 12:50:24   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 12:50:24   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 12:55:07 Training with configuration:
2025-05-13 12:55:07 data:
2025-05-13 12:55:07   bbox_margin: 20
2025-05-13 12:55:07   colormode: RGB
2025-05-13 12:55:07   inference:
2025-05-13 12:55:07     normalize_images: True
2025-05-13 12:55:07   train:
2025-05-13 12:55:07     affine:
2025-05-13 12:55:07       p: 0.5
2025-05-13 12:55:07       rotation: 30
2025-05-13 12:55:07       scaling: [0.5, 1.25]
2025-05-13 12:55:07       translation: 0
2025-05-13 12:55:07     crop_sampling:
2025-05-13 12:55:07       width: 448
2025-05-13 12:55:07       height: 448
2025-05-13 12:55:07       max_shift: 0.1
2025-05-13 12:55:07       method: hybrid
2025-05-13 12:55:07     gaussian_noise: 12.75
2025-05-13 12:55:07     motion_blur: True
2025-05-13 12:55:07     normalize_images: True
2025-05-13 12:55:07 device: auto
2025-05-13 12:55:07 metadata:
2025-05-13 12:55:07   project_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12
2025-05-13 12:55:07   pose_config_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12/dlc-models-pytorch/iteration-0/pigs-heart-rateMay12-trainset95shuffle1/train/pytorch_config.yaml
2025-05-13 12:55:07   bodyparts: ['L ear base', 'R ear base', 'Mid snout']
2025-05-13 12:55:07   unique_bodyparts: []
2025-05-13 12:55:07   individuals: ['animal']
2025-05-13 12:55:07   with_identity: None
2025-05-13 12:55:07 method: bu
2025-05-13 12:55:07 model:
2025-05-13 12:55:07   backbone:
2025-05-13 12:55:07     type: ResNet
2025-05-13 12:55:07     model_name: resnet50_gn
2025-05-13 12:55:07     output_stride: 16
2025-05-13 12:55:07     freeze_bn_stats: False
2025-05-13 12:55:07     freeze_bn_weights: False
2025-05-13 12:55:07   backbone_output_channels: 2048
2025-05-13 12:55:07   heads:
2025-05-13 12:55:07     bodypart:
2025-05-13 12:55:07       type: HeatmapHead
2025-05-13 12:55:07       weight_init: normal
2025-05-13 12:55:07       predictor:
2025-05-13 12:55:07         type: HeatmapPredictor
2025-05-13 12:55:07         apply_sigmoid: False
2025-05-13 12:55:07         clip_scores: True
2025-05-13 12:55:07         location_refinement: True
2025-05-13 12:55:07         locref_std: 7.2801
2025-05-13 12:55:07       target_generator:
2025-05-13 12:55:07         type: HeatmapGaussianGenerator
2025-05-13 12:55:07         num_heatmaps: 3
2025-05-13 12:55:07         pos_dist_thresh: 17
2025-05-13 12:55:07         heatmap_mode: KEYPOINT
2025-05-13 12:55:07         gradient_masking: False
2025-05-13 12:55:07         generate_locref: True
2025-05-13 12:55:07         locref_std: 7.2801
2025-05-13 12:55:07       criterion:
2025-05-13 12:55:07         heatmap:
2025-05-13 12:55:07           type: WeightedMSECriterion
2025-05-13 12:55:07           weight: 1.0
2025-05-13 12:55:07         locref:
2025-05-13 12:55:07           type: WeightedHuberCriterion
2025-05-13 12:55:07           weight: 0.05
2025-05-13 12:55:07       heatmap_config:
2025-05-13 12:55:07         channels: [2048, 3]
2025-05-13 12:55:07         kernel_size: [3]
2025-05-13 12:55:07         strides: [2]
2025-05-13 12:55:07       locref_config:
2025-05-13 12:55:07         channels: [2048, 6]
2025-05-13 12:55:07         kernel_size: [3]
2025-05-13 12:55:07         strides: [2]
2025-05-13 12:55:07 net_type: resnet_50
2025-05-13 12:55:07 runner:
2025-05-13 12:55:07   type: PoseTrainingRunner
2025-05-13 12:55:07   gpus: None
2025-05-13 12:55:07   key_metric: test.mAP
2025-05-13 12:55:07   key_metric_asc: True
2025-05-13 12:55:07   eval_interval: 10
2025-05-13 12:55:07   optimizer:
2025-05-13 12:55:07     type: AdamW
2025-05-13 12:55:07     params:
2025-05-13 12:55:07       lr: 0.0005
2025-05-13 12:55:07   scheduler:
2025-05-13 12:55:07     type: LRListScheduler
2025-05-13 12:55:07     params:
2025-05-13 12:55:07       lr_list: [[0.0001], [1e-05]]
2025-05-13 12:55:07       milestones: [90, 120]
2025-05-13 12:55:07   snapshots:
2025-05-13 12:55:07     max_snapshots: 5
2025-05-13 12:55:07     save_epochs: 5
2025-05-13 12:55:07     save_optimizer_state: False
2025-05-13 12:55:07 train_settings:
2025-05-13 12:55:07   batch_size: 8
2025-05-13 12:55:07   dataloader_workers: 0
2025-05-13 12:55:07   dataloader_pin_memory: False
2025-05-13 12:55:07   display_iters: 500
2025-05-13 12:55:07   epochs: 200
2025-05-13 12:55:07   seed: 42
2025-05-13 12:55:08 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-05-13 12:55:08 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-05-13 12:55:08 Data Transforms:
2025-05-13 12:55:08   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 12:55:08   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 13:00:45 Training with configuration:
2025-05-13 13:00:45 data:
2025-05-13 13:00:45   bbox_margin: 20
2025-05-13 13:00:45   colormode: RGB
2025-05-13 13:00:45   inference:
2025-05-13 13:00:45     normalize_images: True
2025-05-13 13:00:45   train:
2025-05-13 13:00:45     affine:
2025-05-13 13:00:45       p: 0.5
2025-05-13 13:00:45       rotation: 30
2025-05-13 13:00:45       scaling: [0.5, 1.25]
2025-05-13 13:00:45       translation: 0
2025-05-13 13:00:45     crop_sampling:
2025-05-13 13:00:45       width: 448
2025-05-13 13:00:45       height: 448
2025-05-13 13:00:45       max_shift: 0.1
2025-05-13 13:00:45       method: hybrid
2025-05-13 13:00:45     gaussian_noise: 12.75
2025-05-13 13:00:45     motion_blur: True
2025-05-13 13:00:45     normalize_images: True
2025-05-13 13:00:45 device: auto
2025-05-13 13:00:45 metadata:
2025-05-13 13:00:45   project_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12
2025-05-13 13:00:45   pose_config_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12/dlc-models-pytorch/iteration-0/pigs-heart-rateMay12-trainset95shuffle1/train/pytorch_config.yaml
2025-05-13 13:00:45   bodyparts: ['L ear base', 'R ear base', 'Mid snout']
2025-05-13 13:00:45   unique_bodyparts: []
2025-05-13 13:00:45   individuals: ['animal']
2025-05-13 13:00:45   with_identity: None
2025-05-13 13:00:45 method: bu
2025-05-13 13:00:45 model:
2025-05-13 13:00:45   backbone:
2025-05-13 13:00:45     type: ResNet
2025-05-13 13:00:45     model_name: resnet50_gn
2025-05-13 13:00:45     output_stride: 16
2025-05-13 13:00:45     freeze_bn_stats: False
2025-05-13 13:00:45     freeze_bn_weights: False
2025-05-13 13:00:45   backbone_output_channels: 2048
2025-05-13 13:00:45   heads:
2025-05-13 13:00:45     bodypart:
2025-05-13 13:00:45       type: HeatmapHead
2025-05-13 13:00:45       weight_init: normal
2025-05-13 13:00:45       predictor:
2025-05-13 13:00:45         type: HeatmapPredictor
2025-05-13 13:00:45         apply_sigmoid: False
2025-05-13 13:00:45         clip_scores: True
2025-05-13 13:00:45         location_refinement: True
2025-05-13 13:00:45         locref_std: 7.2801
2025-05-13 13:00:45       target_generator:
2025-05-13 13:00:45         type: HeatmapGaussianGenerator
2025-05-13 13:00:45         num_heatmaps: 3
2025-05-13 13:00:45         pos_dist_thresh: 17
2025-05-13 13:00:45         heatmap_mode: KEYPOINT
2025-05-13 13:00:45         gradient_masking: False
2025-05-13 13:00:45         generate_locref: True
2025-05-13 13:00:45         locref_std: 7.2801
2025-05-13 13:00:45       criterion:
2025-05-13 13:00:45         heatmap:
2025-05-13 13:00:45           type: WeightedMSECriterion
2025-05-13 13:00:45           weight: 1.0
2025-05-13 13:00:45         locref:
2025-05-13 13:00:45           type: WeightedHuberCriterion
2025-05-13 13:00:45           weight: 0.05
2025-05-13 13:00:45       heatmap_config:
2025-05-13 13:00:45         channels: [2048, 3]
2025-05-13 13:00:45         kernel_size: [3]
2025-05-13 13:00:45         strides: [2]
2025-05-13 13:00:45       locref_config:
2025-05-13 13:00:45         channels: [2048, 6]
2025-05-13 13:00:45         kernel_size: [3]
2025-05-13 13:00:45         strides: [2]
2025-05-13 13:00:45 net_type: resnet_50
2025-05-13 13:00:45 runner:
2025-05-13 13:00:45   type: PoseTrainingRunner
2025-05-13 13:00:45   gpus: None
2025-05-13 13:00:45   key_metric: test.mAP
2025-05-13 13:00:45   key_metric_asc: True
2025-05-13 13:00:45   eval_interval: 10
2025-05-13 13:00:45   optimizer:
2025-05-13 13:00:45     type: AdamW
2025-05-13 13:00:45     params:
2025-05-13 13:00:45       lr: 0.0005
2025-05-13 13:00:45   scheduler:
2025-05-13 13:00:45     type: LRListScheduler
2025-05-13 13:00:45     params:
2025-05-13 13:00:45       lr_list: [[0.0001], [1e-05]]
2025-05-13 13:00:45       milestones: [90, 120]
2025-05-13 13:00:45   snapshots:
2025-05-13 13:00:45     max_snapshots: 5
2025-05-13 13:00:45     save_epochs: 5
2025-05-13 13:00:45     save_optimizer_state: False
2025-05-13 13:00:45 train_settings:
2025-05-13 13:00:45   batch_size: 8
2025-05-13 13:00:45   dataloader_workers: 0
2025-05-13 13:00:45   dataloader_pin_memory: False
2025-05-13 13:00:45   display_iters: 500
2025-05-13 13:00:45   epochs: 200
2025-05-13 13:00:45   seed: 42
2025-05-13 13:00:46 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-05-13 13:00:46 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-05-13 13:00:46 Data Transforms:
2025-05-13 13:00:46   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 13:00:46   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 13:00:52 Training with configuration:
2025-05-13 13:00:52 data:
2025-05-13 13:00:52   bbox_margin: 20
2025-05-13 13:00:52   colormode: RGB
2025-05-13 13:00:52   inference:
2025-05-13 13:00:52     normalize_images: True
2025-05-13 13:00:52   train:
2025-05-13 13:00:52     affine:
2025-05-13 13:00:52       p: 0.5
2025-05-13 13:00:52       rotation: 30
2025-05-13 13:00:52       scaling: [0.5, 1.25]
2025-05-13 13:00:52       translation: 0
2025-05-13 13:00:52     crop_sampling:
2025-05-13 13:00:52       width: 448
2025-05-13 13:00:52       height: 448
2025-05-13 13:00:52       max_shift: 0.1
2025-05-13 13:00:52       method: hybrid
2025-05-13 13:00:52     gaussian_noise: 12.75
2025-05-13 13:00:52     motion_blur: True
2025-05-13 13:00:52     normalize_images: True
2025-05-13 13:00:52 device: auto
2025-05-13 13:00:52 metadata:
2025-05-13 13:00:52   project_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12
2025-05-13 13:00:52   pose_config_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12/dlc-models-pytorch/iteration-0/pigs-heart-rateMay12-trainset95shuffle1/train/pytorch_config.yaml
2025-05-13 13:00:52   bodyparts: ['L ear base', 'R ear base', 'Mid snout']
2025-05-13 13:00:52   unique_bodyparts: []
2025-05-13 13:00:52   individuals: ['animal']
2025-05-13 13:00:52   with_identity: None
2025-05-13 13:00:52 method: bu
2025-05-13 13:00:52 model:
2025-05-13 13:00:52   backbone:
2025-05-13 13:00:52     type: ResNet
2025-05-13 13:00:52     model_name: resnet50_gn
2025-05-13 13:00:52     output_stride: 16
2025-05-13 13:00:52     freeze_bn_stats: False
2025-05-13 13:00:52     freeze_bn_weights: False
2025-05-13 13:00:52   backbone_output_channels: 2048
2025-05-13 13:00:52   heads:
2025-05-13 13:00:52     bodypart:
2025-05-13 13:00:52       type: HeatmapHead
2025-05-13 13:00:52       weight_init: normal
2025-05-13 13:00:52       predictor:
2025-05-13 13:00:52         type: HeatmapPredictor
2025-05-13 13:00:52         apply_sigmoid: False
2025-05-13 13:00:52         clip_scores: True
2025-05-13 13:00:52         location_refinement: True
2025-05-13 13:00:52         locref_std: 7.2801
2025-05-13 13:00:52       target_generator:
2025-05-13 13:00:52         type: HeatmapGaussianGenerator
2025-05-13 13:00:52         num_heatmaps: 3
2025-05-13 13:00:52         pos_dist_thresh: 17
2025-05-13 13:00:52         heatmap_mode: KEYPOINT
2025-05-13 13:00:52         gradient_masking: False
2025-05-13 13:00:52         generate_locref: True
2025-05-13 13:00:52         locref_std: 7.2801
2025-05-13 13:00:52       criterion:
2025-05-13 13:00:52         heatmap:
2025-05-13 13:00:52           type: WeightedMSECriterion
2025-05-13 13:00:52           weight: 1.0
2025-05-13 13:00:52         locref:
2025-05-13 13:00:52           type: WeightedHuberCriterion
2025-05-13 13:00:52           weight: 0.05
2025-05-13 13:00:52       heatmap_config:
2025-05-13 13:00:52         channels: [2048, 3]
2025-05-13 13:00:52         kernel_size: [3]
2025-05-13 13:00:52         strides: [2]
2025-05-13 13:00:52       locref_config:
2025-05-13 13:00:52         channels: [2048, 6]
2025-05-13 13:00:52         kernel_size: [3]
2025-05-13 13:00:52         strides: [2]
2025-05-13 13:00:52 net_type: resnet_50
2025-05-13 13:00:52 runner:
2025-05-13 13:00:52   type: PoseTrainingRunner
2025-05-13 13:00:52   gpus: None
2025-05-13 13:00:52   key_metric: test.mAP
2025-05-13 13:00:52   key_metric_asc: True
2025-05-13 13:00:52   eval_interval: 10
2025-05-13 13:00:52   optimizer:
2025-05-13 13:00:52     type: AdamW
2025-05-13 13:00:52     params:
2025-05-13 13:00:52       lr: 0.0005
2025-05-13 13:00:52   scheduler:
2025-05-13 13:00:52     type: LRListScheduler
2025-05-13 13:00:52     params:
2025-05-13 13:00:52       lr_list: [[0.0001], [1e-05]]
2025-05-13 13:00:52       milestones: [90, 120]
2025-05-13 13:00:52   snapshots:
2025-05-13 13:00:52     max_snapshots: 5
2025-05-13 13:00:52     save_epochs: 5
2025-05-13 13:00:52     save_optimizer_state: False
2025-05-13 13:00:52 train_settings:
2025-05-13 13:00:52   batch_size: 8
2025-05-13 13:00:52   dataloader_workers: 0
2025-05-13 13:00:52   dataloader_pin_memory: False
2025-05-13 13:00:52   display_iters: 500
2025-05-13 13:00:52   epochs: 200
2025-05-13 13:00:52   seed: 42
2025-05-13 13:00:52 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-05-13 13:00:53 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-05-13 13:00:53 Data Transforms:
2025-05-13 13:00:53   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 13:00:53   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 13:03:15 Training with configuration:
2025-05-13 13:03:15 data:
2025-05-13 13:03:15   bbox_margin: 20
2025-05-13 13:03:15   colormode: RGB
2025-05-13 13:03:15   inference:
2025-05-13 13:03:15     normalize_images: True
2025-05-13 13:03:15   train:
2025-05-13 13:03:15     affine:
2025-05-13 13:03:15       p: 0.5
2025-05-13 13:03:15       rotation: 30
2025-05-13 13:03:15       scaling: [0.5, 1.25]
2025-05-13 13:03:15       translation: 0
2025-05-13 13:03:15     crop_sampling:
2025-05-13 13:03:15       width: 448
2025-05-13 13:03:15       height: 448
2025-05-13 13:03:15       max_shift: 0.1
2025-05-13 13:03:15       method: hybrid
2025-05-13 13:03:15     gaussian_noise: 12.75
2025-05-13 13:03:15     motion_blur: True
2025-05-13 13:03:15     normalize_images: True
2025-05-13 13:03:15 device: auto
2025-05-13 13:03:15 metadata:
2025-05-13 13:03:15   project_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12
2025-05-13 13:03:15   pose_config_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12/dlc-models-pytorch/iteration-0/pigs-heart-rateMay12-trainset95shuffle1/train/pytorch_config.yaml
2025-05-13 13:03:15   bodyparts: ['L ear base', 'R ear base', 'Mid snout']
2025-05-13 13:03:15   unique_bodyparts: []
2025-05-13 13:03:15   individuals: ['animal']
2025-05-13 13:03:15   with_identity: None
2025-05-13 13:03:15 method: bu
2025-05-13 13:03:15 model:
2025-05-13 13:03:15   backbone:
2025-05-13 13:03:15     type: ResNet
2025-05-13 13:03:15     model_name: resnet50_gn
2025-05-13 13:03:15     output_stride: 16
2025-05-13 13:03:15     freeze_bn_stats: False
2025-05-13 13:03:15     freeze_bn_weights: False
2025-05-13 13:03:15   backbone_output_channels: 2048
2025-05-13 13:03:15   heads:
2025-05-13 13:03:15     bodypart:
2025-05-13 13:03:15       type: HeatmapHead
2025-05-13 13:03:15       weight_init: normal
2025-05-13 13:03:15       predictor:
2025-05-13 13:03:15         type: HeatmapPredictor
2025-05-13 13:03:15         apply_sigmoid: False
2025-05-13 13:03:15         clip_scores: True
2025-05-13 13:03:15         location_refinement: True
2025-05-13 13:03:15         locref_std: 7.2801
2025-05-13 13:03:15       target_generator:
2025-05-13 13:03:15         type: HeatmapGaussianGenerator
2025-05-13 13:03:15         num_heatmaps: 3
2025-05-13 13:03:15         pos_dist_thresh: 17
2025-05-13 13:03:15         heatmap_mode: KEYPOINT
2025-05-13 13:03:15         gradient_masking: False
2025-05-13 13:03:15         generate_locref: True
2025-05-13 13:03:15         locref_std: 7.2801
2025-05-13 13:03:15       criterion:
2025-05-13 13:03:15         heatmap:
2025-05-13 13:03:15           type: WeightedMSECriterion
2025-05-13 13:03:15           weight: 1.0
2025-05-13 13:03:15         locref:
2025-05-13 13:03:15           type: WeightedHuberCriterion
2025-05-13 13:03:15           weight: 0.05
2025-05-13 13:03:15       heatmap_config:
2025-05-13 13:03:15         channels: [2048, 3]
2025-05-13 13:03:15         kernel_size: [3]
2025-05-13 13:03:15         strides: [2]
2025-05-13 13:03:15       locref_config:
2025-05-13 13:03:15         channels: [2048, 6]
2025-05-13 13:03:15         kernel_size: [3]
2025-05-13 13:03:15         strides: [2]
2025-05-13 13:03:15 net_type: resnet_50
2025-05-13 13:03:15 runner:
2025-05-13 13:03:15   type: PoseTrainingRunner
2025-05-13 13:03:15   gpus: None
2025-05-13 13:03:15   key_metric: test.mAP
2025-05-13 13:03:15   key_metric_asc: True
2025-05-13 13:03:15   eval_interval: 10
2025-05-13 13:03:15   optimizer:
2025-05-13 13:03:15     type: AdamW
2025-05-13 13:03:15     params:
2025-05-13 13:03:15       lr: 0.0005
2025-05-13 13:03:15   scheduler:
2025-05-13 13:03:15     type: LRListScheduler
2025-05-13 13:03:15     params:
2025-05-13 13:03:15       lr_list: [[0.0001], [1e-05]]
2025-05-13 13:03:15       milestones: [90, 120]
2025-05-13 13:03:15   snapshots:
2025-05-13 13:03:15     max_snapshots: 5
2025-05-13 13:03:15     save_epochs: 5
2025-05-13 13:03:15     save_optimizer_state: False
2025-05-13 13:03:15 train_settings:
2025-05-13 13:03:15   batch_size: 8
2025-05-13 13:03:15   dataloader_workers: 0
2025-05-13 13:03:15   dataloader_pin_memory: False
2025-05-13 13:03:15   display_iters: 500
2025-05-13 13:03:15   epochs: 200
2025-05-13 13:03:15   seed: 42
2025-05-13 13:03:16 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-05-13 13:03:16 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-05-13 13:03:16 Data Transforms:
2025-05-13 13:03:16   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 13:03:16   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 13:03:25 Training with configuration:
2025-05-13 13:03:25 data:
2025-05-13 13:03:25   bbox_margin: 20
2025-05-13 13:03:25   colormode: RGB
2025-05-13 13:03:25   inference:
2025-05-13 13:03:25     normalize_images: True
2025-05-13 13:03:25   train:
2025-05-13 13:03:25     affine:
2025-05-13 13:03:25       p: 0.5
2025-05-13 13:03:25       rotation: 30
2025-05-13 13:03:25       scaling: [0.5, 1.25]
2025-05-13 13:03:25       translation: 0
2025-05-13 13:03:25     crop_sampling:
2025-05-13 13:03:25       width: 448
2025-05-13 13:03:25       height: 448
2025-05-13 13:03:25       max_shift: 0.1
2025-05-13 13:03:25       method: hybrid
2025-05-13 13:03:25     gaussian_noise: 12.75
2025-05-13 13:03:25     motion_blur: True
2025-05-13 13:03:25     normalize_images: True
2025-05-13 13:03:25 device: auto
2025-05-13 13:03:25 metadata:
2025-05-13 13:03:25   project_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12
2025-05-13 13:03:25   pose_config_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12/dlc-models-pytorch/iteration-0/pigs-heart-rateMay12-trainset95shuffle1/train/pytorch_config.yaml
2025-05-13 13:03:25   bodyparts: ['L ear base', 'R ear base', 'Mid snout']
2025-05-13 13:03:25   unique_bodyparts: []
2025-05-13 13:03:25   individuals: ['animal']
2025-05-13 13:03:25   with_identity: None
2025-05-13 13:03:25 method: bu
2025-05-13 13:03:25 model:
2025-05-13 13:03:25   backbone:
2025-05-13 13:03:25     type: ResNet
2025-05-13 13:03:25     model_name: resnet50_gn
2025-05-13 13:03:25     output_stride: 16
2025-05-13 13:03:25     freeze_bn_stats: False
2025-05-13 13:03:25     freeze_bn_weights: False
2025-05-13 13:03:25   backbone_output_channels: 2048
2025-05-13 13:03:25   heads:
2025-05-13 13:03:25     bodypart:
2025-05-13 13:03:25       type: HeatmapHead
2025-05-13 13:03:25       weight_init: normal
2025-05-13 13:03:25       predictor:
2025-05-13 13:03:25         type: HeatmapPredictor
2025-05-13 13:03:25         apply_sigmoid: False
2025-05-13 13:03:25         clip_scores: True
2025-05-13 13:03:25         location_refinement: True
2025-05-13 13:03:25         locref_std: 7.2801
2025-05-13 13:03:25       target_generator:
2025-05-13 13:03:25         type: HeatmapGaussianGenerator
2025-05-13 13:03:25         num_heatmaps: 3
2025-05-13 13:03:25         pos_dist_thresh: 17
2025-05-13 13:03:25         heatmap_mode: KEYPOINT
2025-05-13 13:03:25         gradient_masking: False
2025-05-13 13:03:25         generate_locref: True
2025-05-13 13:03:25         locref_std: 7.2801
2025-05-13 13:03:25       criterion:
2025-05-13 13:03:25         heatmap:
2025-05-13 13:03:25           type: WeightedMSECriterion
2025-05-13 13:03:25           weight: 1.0
2025-05-13 13:03:25         locref:
2025-05-13 13:03:25           type: WeightedHuberCriterion
2025-05-13 13:03:25           weight: 0.05
2025-05-13 13:03:25       heatmap_config:
2025-05-13 13:03:25         channels: [2048, 3]
2025-05-13 13:03:25         kernel_size: [3]
2025-05-13 13:03:25         strides: [2]
2025-05-13 13:03:25       locref_config:
2025-05-13 13:03:25         channels: [2048, 6]
2025-05-13 13:03:25         kernel_size: [3]
2025-05-13 13:03:25         strides: [2]
2025-05-13 13:03:25 net_type: resnet_50
2025-05-13 13:03:25 runner:
2025-05-13 13:03:25   type: PoseTrainingRunner
2025-05-13 13:03:25   gpus: None
2025-05-13 13:03:25   key_metric: test.mAP
2025-05-13 13:03:25   key_metric_asc: True
2025-05-13 13:03:25   eval_interval: 10
2025-05-13 13:03:25   optimizer:
2025-05-13 13:03:25     type: AdamW
2025-05-13 13:03:25     params:
2025-05-13 13:03:25       lr: 0.0005
2025-05-13 13:03:25   scheduler:
2025-05-13 13:03:25     type: LRListScheduler
2025-05-13 13:03:25     params:
2025-05-13 13:03:25       lr_list: [[0.0001], [1e-05]]
2025-05-13 13:03:25       milestones: [90, 120]
2025-05-13 13:03:25   snapshots:
2025-05-13 13:03:25     max_snapshots: 5
2025-05-13 13:03:25     save_epochs: 5
2025-05-13 13:03:25     save_optimizer_state: False
2025-05-13 13:03:25 train_settings:
2025-05-13 13:03:25   batch_size: 8
2025-05-13 13:03:25   dataloader_workers: 0
2025-05-13 13:03:25   dataloader_pin_memory: False
2025-05-13 13:03:25   display_iters: 500
2025-05-13 13:03:25   epochs: 200
2025-05-13 13:03:25   seed: 42
2025-05-13 13:03:26 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-05-13 13:03:26 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-05-13 13:03:26 Data Transforms:
2025-05-13 13:03:26   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 13:03:26   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 13:03:27 Using 110 images and 6 for testing
2025-05-13 13:03:27 
Starting pose model training...
--------------------------------------------------
2025-05-13 13:03:43 Epoch 1/200 (lr=0.0005), train loss 0.01575
2025-05-13 13:03:58 Epoch 2/200 (lr=0.0005), train loss 0.01469
2025-05-13 13:04:13 Epoch 3/200 (lr=0.0005), train loss 0.01435
2025-05-13 13:04:27 Epoch 4/200 (lr=0.0005), train loss 0.01493
2025-05-13 13:04:42 Epoch 5/200 (lr=0.0005), train loss 0.01462
2025-05-13 13:04:57 Epoch 6/200 (lr=0.0005), train loss 0.01454
2025-05-13 13:05:12 Epoch 7/200 (lr=0.0005), train loss 0.01446
2025-05-13 13:05:26 Epoch 8/200 (lr=0.0005), train loss 0.01400
2025-05-13 13:05:41 Epoch 9/200 (lr=0.0005), train loss 0.01360
2025-05-13 13:05:55 Training for epoch 10 done, starting evaluation
2025-05-13 13:05:57 Epoch 10/200 (lr=0.0005), train loss 0.01362, valid loss 0.01438
2025-05-13 13:05:57 Model performance:
2025-05-13 13:05:57   metrics/test.rmse:         322.73
2025-05-13 13:05:57   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:05:57   metrics/test.mAP:            0.00
2025-05-13 13:05:57   metrics/test.mAR:            0.00
2025-05-13 13:06:15 Epoch 11/200 (lr=0.0005), train loss 0.01328
2025-05-13 13:06:31 Epoch 12/200 (lr=0.0005), train loss 0.01187
2025-05-13 13:06:47 Epoch 13/200 (lr=0.0005), train loss 0.01160
2025-05-13 13:07:01 Epoch 14/200 (lr=0.0005), train loss 0.01077
2025-05-13 13:07:17 Epoch 15/200 (lr=0.0005), train loss 0.01081
2025-05-13 13:07:32 Epoch 16/200 (lr=0.0005), train loss 0.00973
2025-05-13 13:07:47 Epoch 17/200 (lr=0.0005), train loss 0.01051
2025-05-13 13:08:05 Epoch 18/200 (lr=0.0005), train loss 0.00904
2025-05-13 13:08:20 Epoch 19/200 (lr=0.0005), train loss 0.00896
2025-05-13 13:08:35 Training for epoch 20 done, starting evaluation
2025-05-13 13:08:36 Epoch 20/200 (lr=0.0005), train loss 0.00873, valid loss 0.00798
2025-05-13 13:08:36 Model performance:
2025-05-13 13:08:36   metrics/test.rmse:         155.19
2025-05-13 13:08:36   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:08:36   metrics/test.mAP:            0.00
2025-05-13 13:08:36   metrics/test.mAR:            0.00
2025-05-13 13:08:51 Epoch 21/200 (lr=0.0005), train loss 0.00761
2025-05-13 13:09:06 Epoch 22/200 (lr=0.0005), train loss 0.00812
2025-05-13 13:09:21 Epoch 23/200 (lr=0.0005), train loss 0.00736
2025-05-13 13:09:35 Epoch 24/200 (lr=0.0005), train loss 0.00763
2025-05-13 13:09:52 Epoch 25/200 (lr=0.0005), train loss 0.00653
2025-05-13 13:10:07 Epoch 26/200 (lr=0.0005), train loss 0.00728
2025-05-13 13:10:22 Epoch 27/200 (lr=0.0005), train loss 0.00720
2025-05-13 13:10:38 Epoch 28/200 (lr=0.0005), train loss 0.00686
2025-05-13 13:10:53 Epoch 29/200 (lr=0.0005), train loss 0.00719
2025-05-13 13:11:08 Training for epoch 30 done, starting evaluation
2025-05-13 13:11:09 Epoch 30/200 (lr=0.0005), train loss 0.00679, valid loss 0.00737
2025-05-13 13:11:09 Model performance:
2025-05-13 13:11:09   metrics/test.rmse:         150.17
2025-05-13 13:11:09   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:11:09   metrics/test.mAP:            0.00
2025-05-13 13:11:09   metrics/test.mAR:            0.00
2025-05-13 13:11:25 Epoch 31/200 (lr=0.0005), train loss 0.00660
2025-05-13 13:11:39 Epoch 32/200 (lr=0.0005), train loss 0.00650
2025-05-13 13:11:54 Epoch 33/200 (lr=0.0005), train loss 0.00660
2025-05-13 13:12:09 Epoch 34/200 (lr=0.0005), train loss 0.00579
2025-05-13 13:12:24 Epoch 35/200 (lr=0.0005), train loss 0.00554
2025-05-13 13:12:39 Epoch 36/200 (lr=0.0005), train loss 0.00590
2025-05-13 13:12:55 Epoch 37/200 (lr=0.0005), train loss 0.00518
2025-05-13 13:13:09 Epoch 38/200 (lr=0.0005), train loss 0.00563
2025-05-13 13:13:24 Epoch 39/200 (lr=0.0005), train loss 0.00566
2025-05-13 13:13:39 Training for epoch 40 done, starting evaluation
2025-05-13 13:13:40 Epoch 40/200 (lr=0.0005), train loss 0.00573, valid loss 0.00888
2025-05-13 13:13:40 Model performance:
2025-05-13 13:13:40   metrics/test.rmse:         142.65
2025-05-13 13:13:40   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:13:40   metrics/test.mAP:            3.93
2025-05-13 13:13:40   metrics/test.mAR:           23.33
2025-05-13 13:13:55 Epoch 41/200 (lr=0.0005), train loss 0.00530
2025-05-13 13:14:10 Epoch 42/200 (lr=0.0005), train loss 0.00630
2025-05-13 13:14:25 Epoch 43/200 (lr=0.0005), train loss 0.00523
2025-05-13 13:14:39 Epoch 44/200 (lr=0.0005), train loss 0.00572
2025-05-13 13:14:54 Epoch 45/200 (lr=0.0005), train loss 0.00584
2025-05-13 13:15:09 Epoch 46/200 (lr=0.0005), train loss 0.00476
2025-05-13 13:15:24 Epoch 47/200 (lr=0.0005), train loss 0.00471
2025-05-13 13:15:38 Epoch 48/200 (lr=0.0005), train loss 0.00442
2025-05-13 13:15:53 Epoch 49/200 (lr=0.0005), train loss 0.00408
2025-05-13 13:16:08 Training for epoch 50 done, starting evaluation
2025-05-13 13:16:09 Epoch 50/200 (lr=0.0005), train loss 0.00452, valid loss 0.00617
2025-05-13 13:16:09 Model performance:
2025-05-13 13:16:09   metrics/test.rmse:          44.57
2025-05-13 13:16:09   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:16:09   metrics/test.mAP:            2.69
2025-05-13 13:16:09   metrics/test.mAR:           13.33
2025-05-13 13:16:24 Epoch 51/200 (lr=0.0005), train loss 0.00422
2025-05-13 13:16:38 Epoch 52/200 (lr=0.0005), train loss 0.00420
2025-05-13 13:16:53 Epoch 53/200 (lr=0.0005), train loss 0.00477
2025-05-13 13:17:07 Epoch 54/200 (lr=0.0005), train loss 0.00451
2025-05-13 13:17:22 Epoch 55/200 (lr=0.0005), train loss 0.00523
2025-05-13 13:17:37 Epoch 56/200 (lr=0.0005), train loss 0.00413
2025-05-13 13:17:51 Epoch 57/200 (lr=0.0005), train loss 0.00487
2025-05-13 13:18:06 Epoch 58/200 (lr=0.0005), train loss 0.00434
2025-05-13 13:18:21 Epoch 59/200 (lr=0.0005), train loss 0.00536
2025-05-13 13:18:36 Training for epoch 60 done, starting evaluation
2025-05-13 13:18:37 Epoch 60/200 (lr=0.0005), train loss 0.00414, valid loss 0.00682
2025-05-13 13:18:37 Model performance:
2025-05-13 13:18:37   metrics/test.rmse:         211.43
2025-05-13 13:18:37   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:18:37   metrics/test.mAP:            0.00
2025-05-13 13:18:37   metrics/test.mAR:            0.00
2025-05-13 13:18:52 Epoch 61/200 (lr=0.0005), train loss 0.00407
2025-05-13 13:19:07 Epoch 62/200 (lr=0.0005), train loss 0.00451
2025-05-13 13:19:22 Epoch 63/200 (lr=0.0005), train loss 0.00391
2025-05-13 13:19:36 Epoch 64/200 (lr=0.0005), train loss 0.00378
2025-05-13 13:19:51 Epoch 65/200 (lr=0.0005), train loss 0.00400
2025-05-13 13:20:06 Epoch 66/200 (lr=0.0005), train loss 0.00338
2025-05-13 13:20:21 Epoch 67/200 (lr=0.0005), train loss 0.00358
2025-05-13 13:20:35 Epoch 68/200 (lr=0.0005), train loss 0.00381
2025-05-13 13:20:50 Epoch 69/200 (lr=0.0005), train loss 0.00385
2025-05-13 13:21:04 Training for epoch 70 done, starting evaluation
2025-05-13 13:21:06 Epoch 70/200 (lr=0.0005), train loss 0.00324, valid loss 0.00790
2025-05-13 13:21:06 Model performance:
2025-05-13 13:21:06   metrics/test.rmse:         109.17
2025-05-13 13:21:06   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:21:06   metrics/test.mAP:            1.35
2025-05-13 13:21:06   metrics/test.mAR:            6.67
2025-05-13 13:21:21 Epoch 71/200 (lr=0.0005), train loss 0.00355
2025-05-13 13:21:36 Epoch 72/200 (lr=0.0005), train loss 0.00356
2025-05-13 13:21:50 Epoch 73/200 (lr=0.0005), train loss 0.00365
2025-05-13 13:22:05 Epoch 74/200 (lr=0.0005), train loss 0.00319
2025-05-13 13:22:20 Epoch 75/200 (lr=0.0005), train loss 0.00402
2025-05-13 13:22:35 Epoch 76/200 (lr=0.0005), train loss 0.00333
2025-05-13 13:22:49 Epoch 77/200 (lr=0.0005), train loss 0.00299
2025-05-13 13:23:04 Epoch 78/200 (lr=0.0005), train loss 0.00278
2025-05-13 13:23:19 Epoch 79/200 (lr=0.0005), train loss 0.00301
2025-05-13 13:23:33 Training for epoch 80 done, starting evaluation
2025-05-13 13:23:35 Epoch 80/200 (lr=0.0005), train loss 0.00262, valid loss 0.00462
2025-05-13 13:23:35 Model performance:
2025-05-13 13:23:35   metrics/test.rmse:         147.37
2025-05-13 13:23:35   metrics/test.rmse_pcutoff:   4.87
2025-05-13 13:23:35   metrics/test.mAP:            0.00
2025-05-13 13:23:35   metrics/test.mAR:            0.00
2025-05-13 13:23:50 Epoch 81/200 (lr=0.0005), train loss 0.00317
2025-05-13 13:24:05 Epoch 82/200 (lr=0.0005), train loss 0.00348
2025-05-13 13:24:20 Epoch 83/200 (lr=0.0005), train loss 0.00310
2025-05-13 13:24:34 Epoch 84/200 (lr=0.0005), train loss 0.00339
2025-05-13 13:24:49 Epoch 85/200 (lr=0.0005), train loss 0.00275
2025-05-13 13:25:04 Epoch 86/200 (lr=0.0005), train loss 0.00231
2025-05-13 13:25:19 Epoch 87/200 (lr=0.0005), train loss 0.00313
2025-05-13 13:25:33 Epoch 88/200 (lr=0.0005), train loss 0.00338
2025-05-13 13:25:48 Epoch 89/200 (lr=0.0005), train loss 0.00304
2025-05-13 13:26:02 Training for epoch 90 done, starting evaluation
2025-05-13 13:26:04 Epoch 90/200 (lr=0.0001), train loss 0.00264, valid loss 0.00630
2025-05-13 13:26:04 Model performance:
2025-05-13 13:26:04   metrics/test.rmse:         103.95
2025-05-13 13:26:04   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:26:04   metrics/test.mAP:            6.06
2025-05-13 13:26:04   metrics/test.mAR:           30.00
2025-05-13 13:26:19 Epoch 91/200 (lr=0.0001), train loss 0.00256
2025-05-13 13:26:34 Epoch 92/200 (lr=0.0001), train loss 0.00255
2025-05-13 13:26:49 Epoch 93/200 (lr=0.0001), train loss 0.00181
2025-05-13 13:27:04 Epoch 94/200 (lr=0.0001), train loss 0.00203
2025-05-13 13:27:19 Epoch 95/200 (lr=0.0001), train loss 0.00207
2025-05-13 13:27:35 Epoch 96/200 (lr=0.0001), train loss 0.00210
2025-05-13 13:27:50 Epoch 97/200 (lr=0.0001), train loss 0.00199
2025-05-13 13:28:05 Epoch 98/200 (lr=0.0001), train loss 0.00208
2025-05-13 13:28:20 Epoch 99/200 (lr=0.0001), train loss 0.00192
2025-05-13 13:28:35 Training for epoch 100 done, starting evaluation
2025-05-13 13:28:36 Epoch 100/200 (lr=0.0001), train loss 0.00172, valid loss 0.00584
2025-05-13 13:28:36 Model performance:
2025-05-13 13:28:36   metrics/test.rmse:           6.15
2025-05-13 13:28:36   metrics/test.rmse_pcutoff:   7.11
2025-05-13 13:28:36   metrics/test.mAP:           31.64
2025-05-13 13:28:36   metrics/test.mAR:           50.00
2025-05-13 13:28:52 Epoch 101/200 (lr=0.0001), train loss 0.00170
2025-05-13 13:38:44 Training with configuration:
2025-05-13 13:38:44 data:
2025-05-13 13:38:44   bbox_margin: 20
2025-05-13 13:38:44   colormode: RGB
2025-05-13 13:38:44   inference:
2025-05-13 13:38:44     normalize_images: True
2025-05-13 13:38:44   train:
2025-05-13 13:38:44     affine:
2025-05-13 13:38:44       p: 0.5
2025-05-13 13:38:44       rotation: 30
2025-05-13 13:38:44       scaling: [0.5, 1.25]
2025-05-13 13:38:44       translation: 0
2025-05-13 13:38:44     crop_sampling:
2025-05-13 13:38:44       width: 448
2025-05-13 13:38:44       height: 448
2025-05-13 13:38:44       max_shift: 0.1
2025-05-13 13:38:44       method: hybrid
2025-05-13 13:38:44     gaussian_noise: 12.75
2025-05-13 13:38:44     motion_blur: True
2025-05-13 13:38:44     normalize_images: True
2025-05-13 13:38:44 device: auto
2025-05-13 13:38:44 metadata:
2025-05-13 13:38:44   project_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12
2025-05-13 13:38:44   pose_config_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12/dlc-models-pytorch/iteration-0/pigs-heart-rateMay12-trainset95shuffle1/train/pytorch_config.yaml
2025-05-13 13:38:44   bodyparts: ['L ear base', 'R ear base', 'Mid snout']
2025-05-13 13:38:44   unique_bodyparts: []
2025-05-13 13:38:44   individuals: ['animal']
2025-05-13 13:38:44   with_identity: None
2025-05-13 13:38:44 method: bu
2025-05-13 13:38:44 model:
2025-05-13 13:38:44   backbone:
2025-05-13 13:38:44     type: ResNet
2025-05-13 13:38:44     model_name: resnet50_gn
2025-05-13 13:38:44     output_stride: 16
2025-05-13 13:38:44     freeze_bn_stats: False
2025-05-13 13:38:44     freeze_bn_weights: False
2025-05-13 13:38:44   backbone_output_channels: 2048
2025-05-13 13:38:44   heads:
2025-05-13 13:38:44     bodypart:
2025-05-13 13:38:44       type: HeatmapHead
2025-05-13 13:38:44       weight_init: normal
2025-05-13 13:38:44       predictor:
2025-05-13 13:38:44         type: HeatmapPredictor
2025-05-13 13:38:44         apply_sigmoid: False
2025-05-13 13:38:44         clip_scores: True
2025-05-13 13:38:44         location_refinement: True
2025-05-13 13:38:44         locref_std: 7.2801
2025-05-13 13:38:44       target_generator:
2025-05-13 13:38:44         type: HeatmapGaussianGenerator
2025-05-13 13:38:44         num_heatmaps: 3
2025-05-13 13:38:44         pos_dist_thresh: 17
2025-05-13 13:38:44         heatmap_mode: KEYPOINT
2025-05-13 13:38:44         gradient_masking: False
2025-05-13 13:38:44         generate_locref: True
2025-05-13 13:38:44         locref_std: 7.2801
2025-05-13 13:38:44       criterion:
2025-05-13 13:38:44         heatmap:
2025-05-13 13:38:44           type: WeightedMSECriterion
2025-05-13 13:38:44           weight: 1.0
2025-05-13 13:38:44         locref:
2025-05-13 13:38:44           type: WeightedHuberCriterion
2025-05-13 13:38:44           weight: 0.05
2025-05-13 13:38:44       heatmap_config:
2025-05-13 13:38:44         channels: [2048, 3]
2025-05-13 13:38:44         kernel_size: [3]
2025-05-13 13:38:44         strides: [2]
2025-05-13 13:38:44       locref_config:
2025-05-13 13:38:44         channels: [2048, 6]
2025-05-13 13:38:44         kernel_size: [3]
2025-05-13 13:38:44         strides: [2]
2025-05-13 13:38:44 net_type: resnet_50
2025-05-13 13:38:44 runner:
2025-05-13 13:38:44   type: PoseTrainingRunner
2025-05-13 13:38:44   gpus: None
2025-05-13 13:38:44   key_metric: test.mAP
2025-05-13 13:38:44   key_metric_asc: True
2025-05-13 13:38:44   eval_interval: 10
2025-05-13 13:38:44   optimizer:
2025-05-13 13:38:44     type: AdamW
2025-05-13 13:38:44     params:
2025-05-13 13:38:44       lr: 0.0005
2025-05-13 13:38:44   scheduler:
2025-05-13 13:38:44     type: LRListScheduler
2025-05-13 13:38:44     params:
2025-05-13 13:38:44       lr_list: [[0.0001], [1e-05]]
2025-05-13 13:38:44       milestones: [90, 120]
2025-05-13 13:38:44   snapshots:
2025-05-13 13:38:44     max_snapshots: 5
2025-05-13 13:38:44     save_epochs: 5
2025-05-13 13:38:44     save_optimizer_state: False
2025-05-13 13:38:44 train_settings:
2025-05-13 13:38:44   batch_size: 8
2025-05-13 13:38:44   dataloader_workers: 0
2025-05-13 13:38:44   dataloader_pin_memory: False
2025-05-13 13:38:44   display_iters: 500
2025-05-13 13:38:44   epochs: 200
2025-05-13 13:38:44   seed: 42
2025-05-13 13:38:44 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-05-13 13:38:45 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-05-13 13:38:45 Data Transforms:
2025-05-13 13:38:45   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 13:38:45   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-05-13 13:38:45 Using 110 images and 6 for testing
2025-05-13 13:38:45 
Starting pose model training...
--------------------------------------------------
2025-05-13 13:39:00 Epoch 1/200 (lr=0.0005), train loss 0.01575
2025-05-13 13:39:14 Epoch 2/200 (lr=0.0005), train loss 0.01469
2025-05-13 13:39:30 Epoch 3/200 (lr=0.0005), train loss 0.01435
2025-05-13 13:39:44 Epoch 4/200 (lr=0.0005), train loss 0.01493
2025-05-13 13:39:59 Epoch 5/200 (lr=0.0005), train loss 0.01462
2025-05-13 13:40:14 Epoch 6/200 (lr=0.0005), train loss 0.01454
2025-05-13 13:40:28 Epoch 7/200 (lr=0.0005), train loss 0.01446
2025-05-13 13:40:43 Epoch 8/200 (lr=0.0005), train loss 0.01400
2025-05-13 13:40:57 Epoch 9/200 (lr=0.0005), train loss 0.01360
2025-05-13 13:41:11 Training for epoch 10 done, starting evaluation
2025-05-13 13:41:13 Epoch 10/200 (lr=0.0005), train loss 0.01362, valid loss 0.01438
2025-05-13 13:41:13 Model performance:
2025-05-13 13:41:13   metrics/test.rmse:         322.73
2025-05-13 13:41:13   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:41:13   metrics/test.mAP:            0.00
2025-05-13 13:41:13   metrics/test.mAR:            0.00
2025-05-13 13:41:28 Epoch 11/200 (lr=0.0005), train loss 0.01328
2025-05-13 13:41:42 Epoch 12/200 (lr=0.0005), train loss 0.01187
2025-05-13 13:41:57 Epoch 13/200 (lr=0.0005), train loss 0.01160
2025-05-13 13:42:12 Epoch 14/200 (lr=0.0005), train loss 0.01077
2025-05-13 13:42:27 Epoch 15/200 (lr=0.0005), train loss 0.01081
2025-05-13 13:42:42 Epoch 16/200 (lr=0.0005), train loss 0.00973
2025-05-13 13:42:56 Epoch 17/200 (lr=0.0005), train loss 0.01051
2025-05-13 13:43:11 Epoch 18/200 (lr=0.0005), train loss 0.00904
2025-05-13 13:43:25 Epoch 19/200 (lr=0.0005), train loss 0.00896
2025-05-13 13:43:40 Training for epoch 20 done, starting evaluation
2025-05-13 13:43:41 Epoch 20/200 (lr=0.0005), train loss 0.00873, valid loss 0.00798
2025-05-13 13:43:42 Model performance:
2025-05-13 13:43:42   metrics/test.rmse:         155.19
2025-05-13 13:43:42   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:43:42   metrics/test.mAP:            0.00
2025-05-13 13:43:42   metrics/test.mAR:            0.00
2025-05-13 13:43:56 Epoch 21/200 (lr=0.0005), train loss 0.00761
2025-05-13 13:44:11 Epoch 22/200 (lr=0.0005), train loss 0.00812
2025-05-13 13:44:25 Epoch 23/200 (lr=0.0005), train loss 0.00736
2025-05-13 13:44:40 Epoch 24/200 (lr=0.0005), train loss 0.00763
2025-05-13 13:44:55 Epoch 25/200 (lr=0.0005), train loss 0.00653
2025-05-13 13:45:10 Epoch 26/200 (lr=0.0005), train loss 0.00728
2025-05-13 13:45:25 Epoch 27/200 (lr=0.0005), train loss 0.00720
2025-05-13 13:45:39 Epoch 28/200 (lr=0.0005), train loss 0.00686
2025-05-13 13:45:54 Epoch 29/200 (lr=0.0005), train loss 0.00719
2025-05-13 13:46:08 Training for epoch 30 done, starting evaluation
2025-05-13 13:46:10 Epoch 30/200 (lr=0.0005), train loss 0.00679, valid loss 0.00737
2025-05-13 13:46:10 Model performance:
2025-05-13 13:46:10   metrics/test.rmse:         150.17
2025-05-13 13:46:10   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:46:10   metrics/test.mAP:            0.00
2025-05-13 13:46:10   metrics/test.mAR:            0.00
2025-05-13 13:46:24 Epoch 31/200 (lr=0.0005), train loss 0.00660
2025-05-13 13:46:39 Epoch 32/200 (lr=0.0005), train loss 0.00650
2025-05-13 13:46:53 Epoch 33/200 (lr=0.0005), train loss 0.00660
2025-05-13 13:47:08 Epoch 34/200 (lr=0.0005), train loss 0.00579
2025-05-13 13:47:23 Epoch 35/200 (lr=0.0005), train loss 0.00554
2025-05-13 13:47:38 Epoch 36/200 (lr=0.0005), train loss 0.00590
2025-05-13 13:47:53 Epoch 37/200 (lr=0.0005), train loss 0.00518
2025-05-13 13:48:07 Epoch 38/200 (lr=0.0005), train loss 0.00563
2025-05-13 13:48:22 Epoch 39/200 (lr=0.0005), train loss 0.00566
2025-05-13 13:48:37 Training for epoch 40 done, starting evaluation
2025-05-13 13:48:38 Epoch 40/200 (lr=0.0005), train loss 0.00573, valid loss 0.00888
2025-05-13 13:48:38 Model performance:
2025-05-13 13:48:38   metrics/test.rmse:         142.65
2025-05-13 13:48:38   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:48:38   metrics/test.mAP:            3.93
2025-05-13 13:48:38   metrics/test.mAR:           23.33
2025-05-13 13:48:53 Epoch 41/200 (lr=0.0005), train loss 0.00530
2025-05-13 13:49:07 Epoch 42/200 (lr=0.0005), train loss 0.00630
2025-05-13 13:49:22 Epoch 43/200 (lr=0.0005), train loss 0.00523
2025-05-13 13:49:37 Epoch 44/200 (lr=0.0005), train loss 0.00572
2025-05-13 13:49:52 Epoch 45/200 (lr=0.0005), train loss 0.00584
2025-05-13 13:50:06 Epoch 46/200 (lr=0.0005), train loss 0.00476
2025-05-13 13:50:21 Epoch 47/200 (lr=0.0005), train loss 0.00471
2025-05-13 13:50:36 Epoch 48/200 (lr=0.0005), train loss 0.00442
2025-05-13 13:50:50 Epoch 49/200 (lr=0.0005), train loss 0.00408
2025-05-13 13:51:05 Training for epoch 50 done, starting evaluation
2025-05-13 13:51:07 Epoch 50/200 (lr=0.0005), train loss 0.00452, valid loss 0.00617
2025-05-13 13:51:07 Model performance:
2025-05-13 13:51:07   metrics/test.rmse:          44.57
2025-05-13 13:51:07   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:51:07   metrics/test.mAP:            2.69
2025-05-13 13:51:07   metrics/test.mAR:           13.33
2025-05-13 13:51:21 Epoch 51/200 (lr=0.0005), train loss 0.00422
2025-05-13 13:51:35 Epoch 52/200 (lr=0.0005), train loss 0.00420
2025-05-13 13:51:49 Epoch 53/200 (lr=0.0005), train loss 0.00477
2025-05-13 13:52:04 Epoch 54/200 (lr=0.0005), train loss 0.00451
2025-05-13 13:52:18 Epoch 55/200 (lr=0.0005), train loss 0.00523
2025-05-13 13:52:33 Epoch 56/200 (lr=0.0005), train loss 0.00413
2025-05-13 13:52:47 Epoch 57/200 (lr=0.0005), train loss 0.00487
2025-05-13 13:53:02 Epoch 58/200 (lr=0.0005), train loss 0.00434
2025-05-13 13:53:16 Epoch 59/200 (lr=0.0005), train loss 0.00536
2025-05-13 13:53:31 Training for epoch 60 done, starting evaluation
2025-05-13 13:53:33 Epoch 60/200 (lr=0.0005), train loss 0.00414, valid loss 0.00682
2025-05-13 13:53:33 Model performance:
2025-05-13 13:53:33   metrics/test.rmse:         211.43
2025-05-13 13:53:33   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:53:33   metrics/test.mAP:            0.00
2025-05-13 13:53:33   metrics/test.mAR:            0.00
2025-05-13 13:53:47 Epoch 61/200 (lr=0.0005), train loss 0.00407
2025-05-13 13:54:02 Epoch 62/200 (lr=0.0005), train loss 0.00451
2025-05-13 13:54:17 Epoch 63/200 (lr=0.0005), train loss 0.00391
2025-05-13 13:54:31 Epoch 64/200 (lr=0.0005), train loss 0.00378
2025-05-13 13:54:46 Epoch 65/200 (lr=0.0005), train loss 0.00400
2025-05-13 13:55:00 Epoch 66/200 (lr=0.0005), train loss 0.00338
2025-05-13 13:55:15 Epoch 67/200 (lr=0.0005), train loss 0.00358
2025-05-13 13:55:30 Epoch 68/200 (lr=0.0005), train loss 0.00381
2025-05-13 13:55:45 Epoch 69/200 (lr=0.0005), train loss 0.00385
2025-05-13 13:55:59 Training for epoch 70 done, starting evaluation
2025-05-13 13:56:01 Epoch 70/200 (lr=0.0005), train loss 0.00324, valid loss 0.00790
2025-05-13 13:56:01 Model performance:
2025-05-13 13:56:01   metrics/test.rmse:         109.17
2025-05-13 13:56:01   metrics/test.rmse_pcutoff:    nan
2025-05-13 13:56:01   metrics/test.mAP:            1.35
2025-05-13 13:56:01   metrics/test.mAR:            6.67
2025-05-13 13:56:15 Epoch 71/200 (lr=0.0005), train loss 0.00355
2025-05-13 13:56:30 Epoch 72/200 (lr=0.0005), train loss 0.00356
2025-05-13 13:56:44 Epoch 73/200 (lr=0.0005), train loss 0.00365
2025-05-13 13:56:59 Epoch 74/200 (lr=0.0005), train loss 0.00319
2025-05-13 13:57:14 Epoch 75/200 (lr=0.0005), train loss 0.00402
2025-05-13 13:57:28 Epoch 76/200 (lr=0.0005), train loss 0.00333
2025-05-13 13:57:43 Epoch 77/200 (lr=0.0005), train loss 0.00299
2025-05-13 13:57:57 Epoch 78/200 (lr=0.0005), train loss 0.00278
2025-05-13 13:58:12 Epoch 79/200 (lr=0.0005), train loss 0.00301
2025-05-13 13:58:27 Training for epoch 80 done, starting evaluation
2025-05-13 13:58:28 Epoch 80/200 (lr=0.0005), train loss 0.00262, valid loss 0.00462
2025-05-13 13:58:28 Model performance:
2025-05-13 13:58:28   metrics/test.rmse:         147.37
2025-05-13 13:58:28   metrics/test.rmse_pcutoff:   4.87
2025-05-13 13:58:28   metrics/test.mAP:            0.00
2025-05-13 13:58:28   metrics/test.mAR:            0.00
2025-05-13 13:58:44 Epoch 81/200 (lr=0.0005), train loss 0.00317
2025-05-13 13:58:58 Epoch 82/200 (lr=0.0005), train loss 0.00348
2025-05-13 13:59:13 Epoch 83/200 (lr=0.0005), train loss 0.00310
2025-05-13 13:59:28 Epoch 84/200 (lr=0.0005), train loss 0.00339
2025-05-13 13:59:43 Epoch 85/200 (lr=0.0005), train loss 0.00275
2025-05-13 13:59:58 Epoch 86/200 (lr=0.0005), train loss 0.00231
2025-05-13 14:00:13 Epoch 87/200 (lr=0.0005), train loss 0.00313
2025-05-13 14:00:27 Epoch 88/200 (lr=0.0005), train loss 0.00338
2025-05-13 14:00:42 Epoch 89/200 (lr=0.0005), train loss 0.00304
2025-05-13 14:00:56 Training for epoch 90 done, starting evaluation
2025-05-13 14:00:57 Epoch 90/200 (lr=0.0001), train loss 0.00264, valid loss 0.00630
2025-05-13 14:00:57 Model performance:
2025-05-13 14:00:57   metrics/test.rmse:         103.95
2025-05-13 14:00:57   metrics/test.rmse_pcutoff:    nan
2025-05-13 14:00:57   metrics/test.mAP:            6.06
2025-05-13 14:00:57   metrics/test.mAR:           30.00
2025-05-13 14:01:13 Epoch 91/200 (lr=0.0001), train loss 0.00256
2025-05-13 14:01:27 Epoch 92/200 (lr=0.0001), train loss 0.00255
2025-05-13 14:01:42 Epoch 93/200 (lr=0.0001), train loss 0.00181
2025-05-13 14:01:56 Epoch 94/200 (lr=0.0001), train loss 0.00203
2025-05-13 14:02:12 Epoch 95/200 (lr=0.0001), train loss 0.00207
2025-05-13 14:02:27 Epoch 96/200 (lr=0.0001), train loss 0.00210
2025-05-13 14:02:42 Epoch 97/200 (lr=0.0001), train loss 0.00199
2025-05-13 14:02:57 Epoch 98/200 (lr=0.0001), train loss 0.00208
2025-05-13 14:03:11 Epoch 99/200 (lr=0.0001), train loss 0.00192
2025-05-13 14:03:25 Training for epoch 100 done, starting evaluation
2025-05-13 14:03:27 Epoch 100/200 (lr=0.0001), train loss 0.00172, valid loss 0.00584
2025-05-13 14:03:27 Model performance:
2025-05-13 14:03:27   metrics/test.rmse:           6.15
2025-05-13 14:03:27   metrics/test.rmse_pcutoff:   7.11
2025-05-13 14:03:27   metrics/test.mAP:           31.64
2025-05-13 14:03:27   metrics/test.mAR:           50.00
2025-05-13 14:03:44 Epoch 101/200 (lr=0.0001), train loss 0.00170
2025-05-13 14:03:59 Epoch 102/200 (lr=0.0001), train loss 0.00148
2025-05-13 14:04:14 Epoch 103/200 (lr=0.0001), train loss 0.00137
2025-05-13 14:04:28 Epoch 104/200 (lr=0.0001), train loss 0.00163
2025-05-13 14:04:43 Epoch 105/200 (lr=0.0001), train loss 0.00185
2025-05-13 14:04:58 Epoch 106/200 (lr=0.0001), train loss 0.00162
2025-05-13 14:05:12 Epoch 107/200 (lr=0.0001), train loss 0.00180
2025-05-13 14:05:27 Epoch 108/200 (lr=0.0001), train loss 0.00181
2025-05-13 14:05:42 Epoch 109/200 (lr=0.0001), train loss 0.00195
2025-05-13 14:05:56 Training for epoch 110 done, starting evaluation
2025-05-13 14:05:58 Epoch 110/200 (lr=0.0001), train loss 0.00172, valid loss 0.00670
2025-05-13 14:05:58 Model performance:
2025-05-13 14:05:58   metrics/test.rmse:         104.19
2025-05-13 14:05:58   metrics/test.rmse_pcutoff:   6.54
2025-05-13 14:05:58   metrics/test.mAP:            5.05
2025-05-13 14:05:58   metrics/test.mAR:           30.00
2025-05-13 14:06:12 Epoch 111/200 (lr=0.0001), train loss 0.00162
2025-05-13 14:06:26 Epoch 112/200 (lr=0.0001), train loss 0.00164
2025-05-13 14:06:41 Epoch 113/200 (lr=0.0001), train loss 0.00124
2025-05-13 14:06:56 Epoch 114/200 (lr=0.0001), train loss 0.00147
2025-05-13 14:07:10 Epoch 115/200 (lr=0.0001), train loss 0.00138
2025-05-13 14:07:26 Epoch 116/200 (lr=0.0001), train loss 0.00132
2025-05-13 14:07:40 Epoch 117/200 (lr=0.0001), train loss 0.00127
2025-05-13 14:07:54 Epoch 118/200 (lr=0.0001), train loss 0.00143
2025-05-13 14:08:09 Epoch 119/200 (lr=0.0001), train loss 0.00120
2025-05-13 14:08:23 Training for epoch 120 done, starting evaluation
2025-05-13 14:08:25 Epoch 120/200 (lr=1e-05), train loss 0.00181, valid loss 0.00553
2025-05-13 14:08:25 Model performance:
2025-05-13 14:08:25   metrics/test.rmse:           6.64
2025-05-13 14:08:25   metrics/test.rmse_pcutoff:   5.86
2025-05-13 14:08:25   metrics/test.mAP:           16.73
2025-05-13 14:08:25   metrics/test.mAR:           40.00
2025-05-13 14:08:39 Epoch 121/200 (lr=1e-05), train loss 0.00144
2025-05-13 14:08:53 Epoch 122/200 (lr=1e-05), train loss 0.00119
2025-05-13 14:09:08 Epoch 123/200 (lr=1e-05), train loss 0.00121
2025-05-13 14:09:22 Epoch 124/200 (lr=1e-05), train loss 0.00165
2025-05-13 14:09:37 Epoch 125/200 (lr=1e-05), train loss 0.00131
2025-05-13 14:09:52 Epoch 126/200 (lr=1e-05), train loss 0.00128
2025-05-13 14:10:06 Epoch 127/200 (lr=1e-05), train loss 0.00148
2025-05-13 14:10:20 Epoch 128/200 (lr=1e-05), train loss 0.00161
2025-05-13 14:10:35 Epoch 129/200 (lr=1e-05), train loss 0.00167
2025-05-13 14:10:50 Training for epoch 130 done, starting evaluation
2025-05-13 14:10:52 Epoch 130/200 (lr=1e-05), train loss 0.00137, valid loss 0.00575
2025-05-13 14:10:52 Model performance:
2025-05-13 14:10:52   metrics/test.rmse:           6.43
2025-05-13 14:10:52   metrics/test.rmse_pcutoff:   5.45
2025-05-13 14:10:52   metrics/test.mAP:           16.73
2025-05-13 14:10:52   metrics/test.mAR:           40.00
2025-05-13 14:11:06 Epoch 131/200 (lr=1e-05), train loss 0.00143
2025-05-13 14:11:21 Epoch 132/200 (lr=1e-05), train loss 0.00147
2025-05-13 14:11:35 Epoch 133/200 (lr=1e-05), train loss 0.00126
2025-05-13 14:11:49 Epoch 134/200 (lr=1e-05), train loss 0.00135
2025-05-13 14:12:04 Epoch 135/200 (lr=1e-05), train loss 0.00159
2025-05-13 14:12:18 Epoch 136/200 (lr=1e-05), train loss 0.00144
2025-05-13 14:12:33 Epoch 137/200 (lr=1e-05), train loss 0.00106
2025-05-13 14:12:47 Epoch 138/200 (lr=1e-05), train loss 0.00127
2025-05-13 14:13:01 Epoch 139/200 (lr=1e-05), train loss 0.00137
2025-05-13 14:13:16 Training for epoch 140 done, starting evaluation
2025-05-13 14:13:18 Epoch 140/200 (lr=1e-05), train loss 0.00119, valid loss 0.00583
2025-05-13 14:13:18 Model performance:
2025-05-13 14:13:18   metrics/test.rmse:           6.85
2025-05-13 14:13:18   metrics/test.rmse_pcutoff:   5.49
2025-05-13 14:13:18   metrics/test.mAP:           16.73
2025-05-13 14:13:18   metrics/test.mAR:           40.00
2025-05-13 14:13:33 Epoch 141/200 (lr=1e-05), train loss 0.00115
2025-05-13 14:13:47 Epoch 142/200 (lr=1e-05), train loss 0.00125
2025-05-13 14:14:01 Epoch 143/200 (lr=1e-05), train loss 0.00132
2025-05-13 14:14:16 Epoch 144/200 (lr=1e-05), train loss 0.00126
2025-05-13 14:14:31 Epoch 145/200 (lr=1e-05), train loss 0.00116
2025-05-13 14:14:46 Epoch 146/200 (lr=1e-05), train loss 0.00135
2025-05-13 14:15:00 Epoch 147/200 (lr=1e-05), train loss 0.00121
2025-05-13 14:15:14 Epoch 148/200 (lr=1e-05), train loss 0.00125
2025-05-13 14:15:29 Epoch 149/200 (lr=1e-05), train loss 0.00148
2025-05-13 14:15:43 Training for epoch 150 done, starting evaluation
2025-05-13 14:15:44 Epoch 150/200 (lr=1e-05), train loss 0.00126, valid loss 0.00590
2025-05-13 14:15:44 Model performance:
2025-05-13 14:15:44   metrics/test.rmse:          45.74
2025-05-13 14:15:44   metrics/test.rmse_pcutoff:   5.63
2025-05-13 14:15:44   metrics/test.mAP:            4.49
2025-05-13 14:15:44   metrics/test.mAR:           26.67
2025-05-13 14:15:59 Epoch 151/200 (lr=1e-05), train loss 0.00128
2025-05-13 14:16:14 Epoch 152/200 (lr=1e-05), train loss 0.00128
2025-05-13 14:16:28 Epoch 153/200 (lr=1e-05), train loss 0.00133
2025-05-13 14:16:42 Epoch 154/200 (lr=1e-05), train loss 0.00144
2025-05-13 14:16:57 Epoch 155/200 (lr=1e-05), train loss 0.00131
2025-05-13 14:17:12 Epoch 156/200 (lr=1e-05), train loss 0.00116
2025-05-13 14:17:26 Epoch 157/200 (lr=1e-05), train loss 0.00140
2025-05-13 14:17:41 Epoch 158/200 (lr=1e-05), train loss 0.00142
2025-05-13 14:17:55 Epoch 159/200 (lr=1e-05), train loss 0.00124
2025-05-13 14:18:09 Training for epoch 160 done, starting evaluation
2025-05-13 14:18:11 Epoch 160/200 (lr=1e-05), train loss 0.00119, valid loss 0.00594
2025-05-13 14:18:11 Model performance:
2025-05-13 14:18:11   metrics/test.rmse:           7.37
2025-05-13 14:18:11   metrics/test.rmse_pcutoff:   5.58
2025-05-13 14:18:11   metrics/test.mAP:           20.07
2025-05-13 14:18:11   metrics/test.mAR:           40.00
2025-05-13 14:18:25 Epoch 161/200 (lr=1e-05), train loss 0.00130
2025-05-13 14:18:40 Epoch 162/200 (lr=1e-05), train loss 0.00160
2025-05-13 14:18:54 Epoch 163/200 (lr=1e-05), train loss 0.00142
2025-05-13 14:19:09 Epoch 164/200 (lr=1e-05), train loss 0.00131
2025-05-13 14:19:24 Epoch 165/200 (lr=1e-05), train loss 0.00137
2025-05-13 14:19:39 Epoch 166/200 (lr=1e-05), train loss 0.00139
2025-05-13 14:19:54 Epoch 167/200 (lr=1e-05), train loss 0.00156
2025-05-13 14:20:08 Epoch 168/200 (lr=1e-05), train loss 0.00122
2025-05-13 14:20:23 Epoch 169/200 (lr=1e-05), train loss 0.00147
2025-05-13 14:20:37 Training for epoch 170 done, starting evaluation
2025-05-13 14:20:39 Epoch 170/200 (lr=1e-05), train loss 0.00137, valid loss 0.00593
2025-05-13 14:20:39 Model performance:
2025-05-13 14:20:39   metrics/test.rmse:           7.45
2025-05-13 14:20:39   metrics/test.rmse_pcutoff:   5.50
2025-05-13 14:20:39   metrics/test.mAP:           16.17
2025-05-13 14:20:39   metrics/test.mAR:           36.67
2025-05-13 14:20:53 Epoch 171/200 (lr=1e-05), train loss 0.00168
2025-05-13 14:21:08 Epoch 172/200 (lr=1e-05), train loss 0.00154
2025-05-13 14:21:22 Epoch 173/200 (lr=1e-05), train loss 0.00112
2025-05-13 14:21:37 Epoch 174/200 (lr=1e-05), train loss 0.00118
2025-05-13 14:21:51 Epoch 175/200 (lr=1e-05), train loss 0.00113
2025-05-13 14:22:05 Epoch 176/200 (lr=1e-05), train loss 0.00112
2025-05-13 14:22:19 Epoch 177/200 (lr=1e-05), train loss 0.00123
2025-05-13 14:22:34 Epoch 178/200 (lr=1e-05), train loss 0.00115
2025-05-13 14:22:49 Epoch 179/200 (lr=1e-05), train loss 0.00139
2025-05-13 14:23:04 Training for epoch 180 done, starting evaluation
2025-05-13 14:23:05 Epoch 180/200 (lr=1e-05), train loss 0.00127, valid loss 0.00606
2025-05-13 14:23:05 Model performance:
2025-05-13 14:23:05   metrics/test.rmse:           7.49
2025-05-13 14:23:05   metrics/test.rmse_pcutoff:   5.50
2025-05-13 14:23:05   metrics/test.mAP:           16.17
2025-05-13 14:23:05   metrics/test.mAR:           36.67
2025-05-13 14:23:20 Epoch 181/200 (lr=1e-05), train loss 0.00131
2025-05-13 14:23:35 Epoch 182/200 (lr=1e-05), train loss 0.00144
2025-05-13 14:23:49 Epoch 183/200 (lr=1e-05), train loss 0.00106
2025-05-13 14:24:03 Epoch 184/200 (lr=1e-05), train loss 0.00115
2025-05-13 14:24:18 Epoch 185/200 (lr=1e-05), train loss 0.00154
2025-05-13 14:24:33 Epoch 186/200 (lr=1e-05), train loss 0.00163
2025-05-13 14:24:47 Epoch 187/200 (lr=1e-05), train loss 0.00150
2025-05-13 14:25:01 Epoch 188/200 (lr=1e-05), train loss 0.00100
2025-05-13 14:25:16 Epoch 189/200 (lr=1e-05), train loss 0.00122
2025-05-13 14:25:31 Training for epoch 190 done, starting evaluation
2025-05-13 14:25:32 Epoch 190/200 (lr=1e-05), train loss 0.00137, valid loss 0.00599
2025-05-13 14:25:32 Model performance:
2025-05-13 14:25:32   metrics/test.rmse:           7.26
2025-05-13 14:25:32   metrics/test.rmse_pcutoff:   5.26
2025-05-13 14:25:32   metrics/test.mAP:           20.07
2025-05-13 14:25:32   metrics/test.mAR:           40.00
2025-05-13 14:25:47 Epoch 191/200 (lr=1e-05), train loss 0.00114
2025-05-13 14:26:02 Epoch 192/200 (lr=1e-05), train loss 0.00123
2025-05-13 14:26:16 Epoch 193/200 (lr=1e-05), train loss 0.00113
2025-05-13 14:26:30 Epoch 194/200 (lr=1e-05), train loss 0.00114
2025-05-13 14:26:45 Epoch 195/200 (lr=1e-05), train loss 0.00118
2025-05-13 14:26:59 Epoch 196/200 (lr=1e-05), train loss 0.00139
2025-05-13 14:27:14 Epoch 197/200 (lr=1e-05), train loss 0.00104
2025-05-13 14:27:28 Epoch 198/200 (lr=1e-05), train loss 0.00142
2025-05-13 14:27:43 Epoch 199/200 (lr=1e-05), train loss 0.00135
2025-05-13 14:27:57 Training for epoch 200 done, starting evaluation
2025-05-13 14:27:59 Epoch 200/200 (lr=1e-05), train loss 0.00103, valid loss 0.00596
2025-05-13 14:27:59 Model performance:
2025-05-13 14:27:59   metrics/test.rmse:           7.53
2025-05-13 14:27:59   metrics/test.rmse_pcutoff:   5.23
2025-05-13 14:27:59   metrics/test.mAP:           16.17
2025-05-13 14:27:59   metrics/test.mAR:           36.67
2025-07-09 00:50:44 Training with configuration:
2025-07-09 00:50:45 data:
2025-07-09 00:50:45   bbox_margin: 20
2025-07-09 00:50:45   colormode: RGB
2025-07-09 00:50:45   inference:
2025-07-09 00:50:45     normalize_images: True
2025-07-09 00:50:45   train:
2025-07-09 00:50:45     affine:
2025-07-09 00:50:45       p: 0.5
2025-07-09 00:50:45       rotation: 30
2025-07-09 00:50:45       scaling: [0.5, 1.25]
2025-07-09 00:50:45       translation: 0
2025-07-09 00:50:45     crop_sampling:
2025-07-09 00:50:45       width: 448
2025-07-09 00:50:45       height: 448
2025-07-09 00:50:45       max_shift: 0.1
2025-07-09 00:50:45       method: hybrid
2025-07-09 00:50:45     gaussian_noise: 12.75
2025-07-09 00:50:45     motion_blur: True
2025-07-09 00:50:45     normalize_images: True
2025-07-09 00:50:45 device: auto
2025-07-09 00:50:45 metadata:
2025-07-09 00:50:45   project_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12
2025-07-09 00:50:45   pose_config_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12/dlc-models-pytorch/iteration-0/pigs-heart-rateMay12-trainset95shuffle1/train/pytorch_config.yaml
2025-07-09 00:50:45   bodyparts: ['L ear base', 'R ear base', 'Mid snout']
2025-07-09 00:50:45   unique_bodyparts: []
2025-07-09 00:50:45   individuals: ['animal']
2025-07-09 00:50:45   with_identity: None
2025-07-09 00:50:45 method: bu
2025-07-09 00:50:45 model:
2025-07-09 00:50:45   backbone:
2025-07-09 00:50:45     type: ResNet
2025-07-09 00:50:45     model_name: resnet50_gn
2025-07-09 00:50:45     output_stride: 16
2025-07-09 00:50:45     freeze_bn_stats: False
2025-07-09 00:50:45     freeze_bn_weights: False
2025-07-09 00:50:45   backbone_output_channels: 2048
2025-07-09 00:50:45   heads:
2025-07-09 00:50:45     bodypart:
2025-07-09 00:50:45       type: HeatmapHead
2025-07-09 00:50:45       weight_init: normal
2025-07-09 00:50:45       predictor:
2025-07-09 00:50:45         type: HeatmapPredictor
2025-07-09 00:50:45         apply_sigmoid: False
2025-07-09 00:50:45         clip_scores: True
2025-07-09 00:50:45         location_refinement: True
2025-07-09 00:50:45         locref_std: 7.2801
2025-07-09 00:50:45       target_generator:
2025-07-09 00:50:45         type: HeatmapGaussianGenerator
2025-07-09 00:50:45         num_heatmaps: 3
2025-07-09 00:50:45         pos_dist_thresh: 17
2025-07-09 00:50:45         heatmap_mode: KEYPOINT
2025-07-09 00:50:45         gradient_masking: False
2025-07-09 00:50:45         generate_locref: True
2025-07-09 00:50:45         locref_std: 7.2801
2025-07-09 00:50:45       criterion:
2025-07-09 00:50:45         heatmap:
2025-07-09 00:50:45           type: WeightedMSECriterion
2025-07-09 00:50:45           weight: 1.0
2025-07-09 00:50:45         locref:
2025-07-09 00:50:45           type: WeightedHuberCriterion
2025-07-09 00:50:45           weight: 0.05
2025-07-09 00:50:45       heatmap_config:
2025-07-09 00:50:45         channels: [2048, 3]
2025-07-09 00:50:45         kernel_size: [3]
2025-07-09 00:50:45         strides: [2]
2025-07-09 00:50:45       locref_config:
2025-07-09 00:50:45         channels: [2048, 6]
2025-07-09 00:50:45         kernel_size: [3]
2025-07-09 00:50:45         strides: [2]
2025-07-09 00:50:45 net_type: resnet_50
2025-07-09 00:50:45 runner:
2025-07-09 00:50:45   type: PoseTrainingRunner
2025-07-09 00:50:45   gpus: None
2025-07-09 00:50:45   key_metric: test.mAP
2025-07-09 00:50:45   key_metric_asc: True
2025-07-09 00:50:45   eval_interval: 10
2025-07-09 00:50:45   optimizer:
2025-07-09 00:50:45     type: AdamW
2025-07-09 00:50:45     params:
2025-07-09 00:50:45       lr: 0.0005
2025-07-09 00:50:45   scheduler:
2025-07-09 00:50:45     type: LRListScheduler
2025-07-09 00:50:45     params:
2025-07-09 00:50:45       lr_list: [[0.0001], [1e-05]]
2025-07-09 00:50:45       milestones: [90, 120]
2025-07-09 00:50:45   snapshots:
2025-07-09 00:50:45     max_snapshots: 5
2025-07-09 00:50:45     save_epochs: 5
2025-07-09 00:50:45     save_optimizer_state: False
2025-07-09 00:50:45 train_settings:
2025-07-09 00:50:45   batch_size: 8
2025-07-09 00:50:45   dataloader_workers: 0
2025-07-09 00:50:45   dataloader_pin_memory: False
2025-07-09 00:50:45   display_iters: 500
2025-07-09 00:50:45   epochs: 200
2025-07-09 00:50:45   seed: 42
2025-07-09 00:50:45 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-07-09 00:50:47 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-07-09 00:50:47 Data Transforms:
2025-07-09 00:50:47   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-07-09 00:50:47   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-07-09 00:50:52 Using 110 images and 6 for testing
2025-07-09 00:50:52 
Starting pose model training...
--------------------------------------------------
2025-07-09 00:52:01 Epoch 1/200 (lr=0.0005), train loss 0.01575
2025-07-09 00:52:15 Epoch 2/200 (lr=0.0005), train loss 0.01469
2025-07-09 00:52:29 Epoch 3/200 (lr=0.0005), train loss 0.01435
2025-07-09 00:52:43 Epoch 4/200 (lr=0.0005), train loss 0.01493
2025-07-09 00:52:57 Epoch 5/200 (lr=0.0005), train loss 0.01462
2025-07-09 00:53:10 Epoch 6/200 (lr=0.0005), train loss 0.01454
2025-07-09 00:53:24 Epoch 7/200 (lr=0.0005), train loss 0.01446
2025-07-09 00:53:38 Epoch 8/200 (lr=0.0005), train loss 0.01400
2025-07-09 00:53:52 Epoch 9/200 (lr=0.0005), train loss 0.01360
2025-07-09 00:54:06 Training for epoch 10 done, starting evaluation
2025-07-09 00:54:11 Epoch 10/200 (lr=0.0005), train loss 0.01362, valid loss 0.01438
2025-07-09 00:54:11 Model performance:
2025-07-09 00:54:11   metrics/test.rmse:         322.73
2025-07-09 00:54:11   metrics/test.rmse_pcutoff:    nan
2025-07-09 00:54:11   metrics/test.mAP:            0.00
2025-07-09 00:54:11   metrics/test.mAR:            0.00
2025-07-09 00:54:25 Epoch 11/200 (lr=0.0005), train loss 0.01328
2025-07-09 00:54:38 Epoch 12/200 (lr=0.0005), train loss 0.01187
2025-07-09 00:54:52 Epoch 13/200 (lr=0.0005), train loss 0.01160
2025-07-09 00:55:07 Epoch 14/200 (lr=0.0005), train loss 0.01077
2025-07-09 00:55:21 Epoch 15/200 (lr=0.0005), train loss 0.01081
2025-07-09 00:55:35 Epoch 16/200 (lr=0.0005), train loss 0.00973
2025-07-09 00:55:49 Epoch 17/200 (lr=0.0005), train loss 0.01051
2025-07-09 00:56:03 Epoch 18/200 (lr=0.0005), train loss 0.00904
2025-07-09 00:56:17 Epoch 19/200 (lr=0.0005), train loss 0.00896
2025-07-09 00:56:31 Training for epoch 20 done, starting evaluation
2025-07-09 00:56:32 Epoch 20/200 (lr=0.0005), train loss 0.00873, valid loss 0.00798
2025-07-09 00:56:32 Model performance:
2025-07-09 00:56:32   metrics/test.rmse:         155.19
2025-07-09 00:56:32   metrics/test.rmse_pcutoff:    nan
2025-07-09 00:56:32   metrics/test.mAP:            0.00
2025-07-09 00:56:32   metrics/test.mAR:            0.00
2025-07-09 00:56:46 Epoch 21/200 (lr=0.0005), train loss 0.00761
2025-07-09 00:57:00 Epoch 22/200 (lr=0.0005), train loss 0.00812
2025-07-09 00:57:14 Epoch 23/200 (lr=0.0005), train loss 0.00736
2025-07-09 00:57:28 Epoch 24/200 (lr=0.0005), train loss 0.00763
2025-07-09 00:57:42 Epoch 25/200 (lr=0.0005), train loss 0.00653
2025-07-09 00:57:56 Epoch 26/200 (lr=0.0005), train loss 0.00728
2025-07-09 00:58:10 Epoch 27/200 (lr=0.0005), train loss 0.00720
2025-07-09 00:58:24 Epoch 28/200 (lr=0.0005), train loss 0.00686
2025-07-09 00:58:39 Epoch 29/200 (lr=0.0005), train loss 0.00719
2025-07-09 00:58:53 Training for epoch 30 done, starting evaluation
2025-07-09 00:58:54 Epoch 30/200 (lr=0.0005), train loss 0.00679, valid loss 0.00737
2025-07-09 00:58:54 Model performance:
2025-07-09 00:58:54   metrics/test.rmse:         150.17
2025-07-09 00:58:54   metrics/test.rmse_pcutoff:    nan
2025-07-09 00:58:54   metrics/test.mAP:            0.00
2025-07-09 00:58:54   metrics/test.mAR:            0.00
2025-07-09 00:59:08 Epoch 31/200 (lr=0.0005), train loss 0.00660
2025-07-09 00:59:22 Epoch 32/200 (lr=0.0005), train loss 0.00650
2025-07-09 00:59:36 Epoch 33/200 (lr=0.0005), train loss 0.00660
2025-07-09 00:59:50 Epoch 34/200 (lr=0.0005), train loss 0.00579
2025-07-09 01:00:04 Epoch 35/200 (lr=0.0005), train loss 0.00554
2025-07-09 01:00:18 Epoch 36/200 (lr=0.0005), train loss 0.00590
2025-07-09 01:00:32 Epoch 37/200 (lr=0.0005), train loss 0.00518
2025-07-09 01:00:46 Epoch 38/200 (lr=0.0005), train loss 0.00563
2025-07-09 01:01:00 Epoch 39/200 (lr=0.0005), train loss 0.00566
2025-07-09 01:01:14 Training for epoch 40 done, starting evaluation
2025-07-09 01:01:15 Epoch 40/200 (lr=0.0005), train loss 0.00573, valid loss 0.00888
2025-07-09 01:01:15 Model performance:
2025-07-09 01:01:15   metrics/test.rmse:         142.65
2025-07-09 01:01:15   metrics/test.rmse_pcutoff:    nan
2025-07-09 01:01:15   metrics/test.mAP:            3.93
2025-07-09 01:01:15   metrics/test.mAR:           23.33
2025-07-09 01:01:29 Epoch 41/200 (lr=0.0005), train loss 0.00530
2025-07-09 01:01:43 Epoch 42/200 (lr=0.0005), train loss 0.00630
2025-07-09 01:01:57 Epoch 43/200 (lr=0.0005), train loss 0.00523
2025-07-09 01:02:11 Epoch 44/200 (lr=0.0005), train loss 0.00572
2025-07-09 01:02:26 Epoch 45/200 (lr=0.0005), train loss 0.00584
2025-07-09 01:02:40 Epoch 46/200 (lr=0.0005), train loss 0.00476
2025-07-09 01:02:54 Epoch 47/200 (lr=0.0005), train loss 0.00471
2025-07-09 01:03:08 Epoch 48/200 (lr=0.0005), train loss 0.00442
2025-07-09 01:03:22 Epoch 49/200 (lr=0.0005), train loss 0.00408
2025-07-09 01:03:35 Training for epoch 50 done, starting evaluation
2025-07-09 01:03:36 Epoch 50/200 (lr=0.0005), train loss 0.00452, valid loss 0.00617
2025-07-09 01:03:36 Model performance:
2025-07-09 01:03:36   metrics/test.rmse:          44.57
2025-07-09 01:03:36   metrics/test.rmse_pcutoff:    nan
2025-07-09 01:03:36   metrics/test.mAP:            2.69
2025-07-09 01:03:36   metrics/test.mAR:           13.33
2025-07-09 01:03:50 Epoch 51/200 (lr=0.0005), train loss 0.00422
2025-07-09 01:04:04 Epoch 52/200 (lr=0.0005), train loss 0.00420
2025-07-09 01:04:17 Epoch 53/200 (lr=0.0005), train loss 0.00477
2025-07-09 01:04:31 Epoch 54/200 (lr=0.0005), train loss 0.00451
2025-07-09 01:04:45 Epoch 55/200 (lr=0.0005), train loss 0.00523
2025-07-09 01:04:59 Epoch 56/200 (lr=0.0005), train loss 0.00413
2025-07-09 01:05:12 Epoch 57/200 (lr=0.0005), train loss 0.00487
2025-07-09 01:05:26 Epoch 58/200 (lr=0.0005), train loss 0.00434
2025-07-09 01:05:40 Epoch 59/200 (lr=0.0005), train loss 0.00536
2025-07-09 01:05:55 Training for epoch 60 done, starting evaluation
2025-07-09 01:05:56 Epoch 60/200 (lr=0.0005), train loss 0.00414, valid loss 0.00682
2025-07-09 01:05:56 Model performance:
2025-07-09 01:05:56   metrics/test.rmse:         211.43
2025-07-09 01:05:56   metrics/test.rmse_pcutoff:    nan
2025-07-09 01:05:56   metrics/test.mAP:            0.00
2025-07-09 01:05:56   metrics/test.mAR:            0.00
2025-07-09 01:06:10 Epoch 61/200 (lr=0.0005), train loss 0.00407
2025-07-09 01:06:24 Epoch 62/200 (lr=0.0005), train loss 0.00451
2025-07-09 01:06:38 Epoch 63/200 (lr=0.0005), train loss 0.00391
2025-07-09 01:06:51 Epoch 64/200 (lr=0.0005), train loss 0.00378
2025-07-09 01:07:06 Epoch 65/200 (lr=0.0005), train loss 0.00400
2025-07-09 01:07:19 Epoch 66/200 (lr=0.0005), train loss 0.00338
2025-07-09 01:07:33 Epoch 67/200 (lr=0.0005), train loss 0.00358
2025-07-09 01:07:47 Epoch 68/200 (lr=0.0005), train loss 0.00381
2025-07-09 01:08:01 Epoch 69/200 (lr=0.0005), train loss 0.00385
2025-07-09 01:08:14 Training for epoch 70 done, starting evaluation
2025-07-09 01:08:16 Epoch 70/200 (lr=0.0005), train loss 0.00324, valid loss 0.00790
2025-07-09 01:08:16 Model performance:
2025-07-09 01:08:16   metrics/test.rmse:         109.17
2025-07-09 01:08:16   metrics/test.rmse_pcutoff:    nan
2025-07-09 01:08:16   metrics/test.mAP:            1.35
2025-07-09 01:08:16   metrics/test.mAR:            6.67
2025-07-09 01:08:30 Epoch 71/200 (lr=0.0005), train loss 0.00355
2025-07-09 01:08:44 Epoch 72/200 (lr=0.0005), train loss 0.00356
2025-07-09 01:08:58 Epoch 73/200 (lr=0.0005), train loss 0.00365
2025-07-09 02:01:20 Training with configuration:
2025-07-09 02:01:21 data:
2025-07-09 02:01:21   bbox_margin: 20
2025-07-09 02:01:21   colormode: RGB
2025-07-09 02:01:21   inference:
2025-07-09 02:01:21     normalize_images: True
2025-07-09 02:01:21   train:
2025-07-09 02:01:21     affine:
2025-07-09 02:01:21       p: 0.5
2025-07-09 02:01:21       rotation: 30
2025-07-09 02:01:21       scaling: [0.5, 1.25]
2025-07-09 02:01:21       translation: 0
2025-07-09 02:01:21     crop_sampling:
2025-07-09 02:01:21       width: 448
2025-07-09 02:01:21       height: 448
2025-07-09 02:01:21       max_shift: 0.1
2025-07-09 02:01:21       method: hybrid
2025-07-09 02:01:21     gaussian_noise: 12.75
2025-07-09 02:01:21     motion_blur: True
2025-07-09 02:01:21     normalize_images: True
2025-07-09 02:01:21 device: auto
2025-07-09 02:01:21 metadata:
2025-07-09 02:01:21   project_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12
2025-07-09 02:01:21   pose_config_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12/dlc-models-pytorch/iteration-0/pigs-heart-rateMay12-trainset95shuffle1/train/pytorch_config.yaml
2025-07-09 02:01:21   bodyparts: ['L ear base', 'R ear base', 'Mid snout']
2025-07-09 02:01:21   unique_bodyparts: []
2025-07-09 02:01:21   individuals: ['animal']
2025-07-09 02:01:21   with_identity: None
2025-07-09 02:01:21 method: bu
2025-07-09 02:01:21 model:
2025-07-09 02:01:21   backbone:
2025-07-09 02:01:21     type: ResNet
2025-07-09 02:01:21     model_name: resnet50_gn
2025-07-09 02:01:21     output_stride: 16
2025-07-09 02:01:21     freeze_bn_stats: False
2025-07-09 02:01:21     freeze_bn_weights: False
2025-07-09 02:01:21   backbone_output_channels: 2048
2025-07-09 02:01:21   heads:
2025-07-09 02:01:21     bodypart:
2025-07-09 02:01:21       type: HeatmapHead
2025-07-09 02:01:21       weight_init: normal
2025-07-09 02:01:21       predictor:
2025-07-09 02:01:21         type: HeatmapPredictor
2025-07-09 02:01:21         apply_sigmoid: False
2025-07-09 02:01:21         clip_scores: True
2025-07-09 02:01:21         location_refinement: True
2025-07-09 02:01:21         locref_std: 7.2801
2025-07-09 02:01:21       target_generator:
2025-07-09 02:01:21         type: HeatmapGaussianGenerator
2025-07-09 02:01:21         num_heatmaps: 3
2025-07-09 02:01:21         pos_dist_thresh: 17
2025-07-09 02:01:21         heatmap_mode: KEYPOINT
2025-07-09 02:01:21         gradient_masking: False
2025-07-09 02:01:21         generate_locref: True
2025-07-09 02:01:21         locref_std: 7.2801
2025-07-09 02:01:21       criterion:
2025-07-09 02:01:21         heatmap:
2025-07-09 02:01:21           type: WeightedMSECriterion
2025-07-09 02:01:21           weight: 1.0
2025-07-09 02:01:21         locref:
2025-07-09 02:01:21           type: WeightedHuberCriterion
2025-07-09 02:01:21           weight: 0.05
2025-07-09 02:01:21       heatmap_config:
2025-07-09 02:01:21         channels: [2048, 3]
2025-07-09 02:01:21         kernel_size: [3]
2025-07-09 02:01:21         strides: [2]
2025-07-09 02:01:21       locref_config:
2025-07-09 02:01:21         channels: [2048, 6]
2025-07-09 02:01:21         kernel_size: [3]
2025-07-09 02:01:21         strides: [2]
2025-07-09 02:01:21 net_type: resnet_50
2025-07-09 02:01:21 runner:
2025-07-09 02:01:21   type: PoseTrainingRunner
2025-07-09 02:01:21   gpus: None
2025-07-09 02:01:21   key_metric: test.mAP
2025-07-09 02:01:21   key_metric_asc: True
2025-07-09 02:01:21   eval_interval: 10
2025-07-09 02:01:21   optimizer:
2025-07-09 02:01:21     type: AdamW
2025-07-09 02:01:21     params:
2025-07-09 02:01:21       lr: 0.0005
2025-07-09 02:01:21   scheduler:
2025-07-09 02:01:21     type: LRListScheduler
2025-07-09 02:01:21     params:
2025-07-09 02:01:21       lr_list: [[0.0001], [1e-05]]
2025-07-09 02:01:21       milestones: [90, 120]
2025-07-09 02:01:21   snapshots:
2025-07-09 02:01:21     max_snapshots: 5
2025-07-09 02:01:21     save_epochs: 5
2025-07-09 02:01:21     save_optimizer_state: False
2025-07-09 02:01:21 train_settings:
2025-07-09 02:01:21   batch_size: 8
2025-07-09 02:01:21   dataloader_workers: 0
2025-07-09 02:01:21   dataloader_pin_memory: False
2025-07-09 02:01:21   display_iters: 500
2025-07-09 02:01:21   epochs: 200
2025-07-09 02:01:21   seed: 42
2025-07-09 02:01:21 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-07-09 02:01:23 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-07-09 02:01:23 Data Transforms:
2025-07-09 02:01:23   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-07-09 02:01:23   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-07-09 02:01:27 Using 110 images and 6 for testing
2025-07-09 02:01:27 
Starting pose model training...
--------------------------------------------------
2025-07-09 02:02:33 Epoch 1/200 (lr=0.0005), train loss 0.01575
2025-07-09 02:02:47 Epoch 2/200 (lr=0.0005), train loss 0.01469
2025-07-09 02:03:00 Epoch 3/200 (lr=0.0005), train loss 0.01435
2025-07-09 02:03:14 Epoch 4/200 (lr=0.0005), train loss 0.01493
2025-07-09 02:03:27 Epoch 5/200 (lr=0.0005), train loss 0.01462
2025-07-09 02:03:41 Epoch 6/200 (lr=0.0005), train loss 0.01454
2025-07-09 02:03:54 Epoch 7/200 (lr=0.0005), train loss 0.01446
2025-07-09 02:04:07 Epoch 8/200 (lr=0.0005), train loss 0.01400
2025-07-09 02:04:21 Epoch 9/200 (lr=0.0005), train loss 0.01360
2025-07-09 02:04:34 Training for epoch 10 done, starting evaluation
2025-07-09 02:04:38 Epoch 10/200 (lr=0.0005), train loss 0.01362, valid loss 0.01438
2025-07-09 02:04:38 Model performance:
2025-07-09 02:04:38   metrics/test.rmse:         322.73
2025-07-09 02:04:38   metrics/test.rmse_pcutoff:    nan
2025-07-09 02:04:38   metrics/test.mAP:            0.00
2025-07-09 02:04:38   metrics/test.mAR:            0.00
2025-07-09 02:04:53 Epoch 11/200 (lr=0.0005), train loss 0.01328
2025-07-09 02:05:06 Epoch 12/200 (lr=0.0005), train loss 0.01187
2025-07-09 02:05:19 Epoch 13/200 (lr=0.0005), train loss 0.01160
2025-07-09 02:05:33 Epoch 14/200 (lr=0.0005), train loss 0.01077
2025-07-09 02:05:47 Epoch 15/200 (lr=0.0005), train loss 0.01081
2025-07-09 02:06:00 Epoch 16/200 (lr=0.0005), train loss 0.00973
2025-07-09 02:06:14 Epoch 17/200 (lr=0.0005), train loss 0.01051
2025-07-09 02:06:28 Epoch 18/200 (lr=0.0005), train loss 0.00904
2025-07-09 02:06:41 Epoch 19/200 (lr=0.0005), train loss 0.00896
2025-07-09 02:06:55 Training for epoch 20 done, starting evaluation
2025-07-09 02:06:56 Epoch 20/200 (lr=0.0005), train loss 0.00873, valid loss 0.00798
2025-07-09 02:06:56 Model performance:
2025-07-09 02:06:56   metrics/test.rmse:         155.19
2025-07-09 02:06:56   metrics/test.rmse_pcutoff:    nan
2025-07-09 02:06:56   metrics/test.mAP:            0.00
2025-07-09 02:06:56   metrics/test.mAR:            0.00
2025-07-09 02:07:09 Epoch 21/200 (lr=0.0005), train loss 0.00761
2025-07-09 02:07:23 Epoch 22/200 (lr=0.0005), train loss 0.00812
2025-07-09 02:07:37 Epoch 23/200 (lr=0.0005), train loss 0.00736
2025-07-09 02:07:51 Epoch 24/200 (lr=0.0005), train loss 0.00763
2025-07-09 02:08:05 Epoch 25/200 (lr=0.0005), train loss 0.00653
2025-07-09 02:08:19 Epoch 26/200 (lr=0.0005), train loss 0.00728
2025-07-09 02:08:32 Epoch 27/200 (lr=0.0005), train loss 0.00720
2025-07-09 02:08:46 Epoch 28/200 (lr=0.0005), train loss 0.00686
2025-07-09 02:08:59 Epoch 29/200 (lr=0.0005), train loss 0.00719
2025-07-09 02:09:13 Training for epoch 30 done, starting evaluation
2025-07-09 02:09:15 Epoch 30/200 (lr=0.0005), train loss 0.00679, valid loss 0.00737
2025-07-09 02:09:15 Model performance:
2025-07-09 02:09:15   metrics/test.rmse:         150.17
2025-07-09 02:09:15   metrics/test.rmse_pcutoff:    nan
2025-07-09 02:09:15   metrics/test.mAP:            0.00
2025-07-09 02:09:15   metrics/test.mAR:            0.00
2025-07-09 02:09:28 Epoch 31/200 (lr=0.0005), train loss 0.00660
2025-07-09 02:09:41 Epoch 32/200 (lr=0.0005), train loss 0.00650
2025-07-09 02:09:55 Epoch 33/200 (lr=0.0005), train loss 0.00660
2025-07-09 02:10:09 Epoch 34/200 (lr=0.0005), train loss 0.00579
2025-07-09 02:10:22 Epoch 35/200 (lr=0.0005), train loss 0.00554
2025-07-09 02:10:36 Epoch 36/200 (lr=0.0005), train loss 0.00590
2025-07-09 02:10:50 Epoch 37/200 (lr=0.0005), train loss 0.00518
2025-07-09 02:11:04 Epoch 38/200 (lr=0.0005), train loss 0.00563
2025-07-09 02:11:17 Epoch 39/200 (lr=0.0005), train loss 0.00566
2025-07-09 02:11:31 Training for epoch 40 done, starting evaluation
2025-07-09 02:11:32 Epoch 40/200 (lr=0.0005), train loss 0.00573, valid loss 0.00888
2025-07-09 02:11:32 Model performance:
2025-07-09 02:11:32   metrics/test.rmse:         142.65
2025-07-09 02:11:32   metrics/test.rmse_pcutoff:    nan
2025-07-09 02:11:32   metrics/test.mAP:            3.93
2025-07-09 02:11:32   metrics/test.mAR:           23.33
2025-07-09 02:11:46 Epoch 41/200 (lr=0.0005), train loss 0.00530
2025-07-09 02:11:59 Epoch 42/200 (lr=0.0005), train loss 0.00630
2025-07-09 02:12:13 Epoch 43/200 (lr=0.0005), train loss 0.00523
2025-07-09 02:12:26 Epoch 44/200 (lr=0.0005), train loss 0.00572
2025-07-09 02:12:40 Epoch 45/200 (lr=0.0005), train loss 0.00584
2025-07-09 02:12:54 Epoch 46/200 (lr=0.0005), train loss 0.00476
2025-07-09 02:13:07 Epoch 47/200 (lr=0.0005), train loss 0.00471
2025-07-09 02:13:21 Epoch 48/200 (lr=0.0005), train loss 0.00442
2025-07-09 02:13:34 Epoch 49/200 (lr=0.0005), train loss 0.00408
2025-07-09 02:13:48 Training for epoch 50 done, starting evaluation
2025-07-09 02:13:49 Epoch 50/200 (lr=0.0005), train loss 0.00452, valid loss 0.00617
2025-07-09 02:13:49 Model performance:
2025-07-09 02:13:49   metrics/test.rmse:          44.57
2025-07-09 02:13:49   metrics/test.rmse_pcutoff:    nan
2025-07-09 02:13:49   metrics/test.mAP:            2.69
2025-07-09 02:13:49   metrics/test.mAR:           13.33
2025-07-09 02:14:03 Epoch 51/200 (lr=0.0005), train loss 0.00422
2025-07-09 02:14:16 Epoch 52/200 (lr=0.0005), train loss 0.00420
2025-07-09 02:14:30 Epoch 53/200 (lr=0.0005), train loss 0.00477
2025-07-09 02:14:44 Epoch 54/200 (lr=0.0005), train loss 0.00451
2025-07-09 02:14:57 Epoch 55/200 (lr=0.0005), train loss 0.00523
2025-07-09 02:15:11 Epoch 56/200 (lr=0.0005), train loss 0.00413
2025-07-09 02:15:25 Epoch 57/200 (lr=0.0005), train loss 0.00487
2025-07-09 02:15:38 Epoch 58/200 (lr=0.0005), train loss 0.00434
2025-07-09 02:15:52 Epoch 59/200 (lr=0.0005), train loss 0.00536
2025-07-09 02:16:06 Training for epoch 60 done, starting evaluation
2025-07-09 02:16:07 Epoch 60/200 (lr=0.0005), train loss 0.00414, valid loss 0.00682
2025-07-09 02:16:07 Model performance:
2025-07-09 02:16:07   metrics/test.rmse:         211.43
2025-07-09 02:16:07   metrics/test.rmse_pcutoff:    nan
2025-07-09 02:16:07   metrics/test.mAP:            0.00
2025-07-09 02:16:07   metrics/test.mAR:            0.00
2025-07-09 02:16:21 Epoch 61/200 (lr=0.0005), train loss 0.00407
2025-07-09 02:16:35 Epoch 62/200 (lr=0.0005), train loss 0.00451
2025-07-09 02:16:48 Epoch 63/200 (lr=0.0005), train loss 0.00391
2025-07-09 02:17:02 Epoch 64/200 (lr=0.0005), train loss 0.00378
2025-07-09 02:17:17 Epoch 65/200 (lr=0.0005), train loss 0.00400
2025-07-09 02:17:30 Epoch 66/200 (lr=0.0005), train loss 0.00338
2025-07-09 02:17:44 Epoch 67/200 (lr=0.0005), train loss 0.00358
2025-07-09 02:17:57 Epoch 68/200 (lr=0.0005), train loss 0.00381
2025-07-09 02:18:11 Epoch 69/200 (lr=0.0005), train loss 0.00385
2025-07-09 02:18:25 Training for epoch 70 done, starting evaluation
2025-07-09 02:18:26 Epoch 70/200 (lr=0.0005), train loss 0.00324, valid loss 0.00790
2025-07-09 02:18:26 Model performance:
2025-07-09 02:18:26   metrics/test.rmse:         109.17
2025-07-09 02:18:26   metrics/test.rmse_pcutoff:    nan
2025-07-09 02:18:26   metrics/test.mAP:            1.35
2025-07-09 02:18:26   metrics/test.mAR:            6.67
2025-07-09 02:18:40 Epoch 71/200 (lr=0.0005), train loss 0.00355
2025-07-09 02:18:53 Epoch 72/200 (lr=0.0005), train loss 0.00356
2025-07-09 02:19:07 Epoch 73/200 (lr=0.0005), train loss 0.00365
2025-07-09 02:19:20 Epoch 74/200 (lr=0.0005), train loss 0.00319
2025-07-09 02:19:34 Epoch 75/200 (lr=0.0005), train loss 0.00402
2025-07-09 02:19:47 Epoch 76/200 (lr=0.0005), train loss 0.00333
2025-07-09 02:20:01 Epoch 77/200 (lr=0.0005), train loss 0.00299
2025-07-09 02:20:15 Epoch 78/200 (lr=0.0005), train loss 0.00278
2025-07-09 02:20:29 Epoch 79/200 (lr=0.0005), train loss 0.00301
2025-07-09 02:20:42 Training for epoch 80 done, starting evaluation
2025-07-09 02:20:44 Epoch 80/200 (lr=0.0005), train loss 0.00262, valid loss 0.00462
2025-07-09 02:20:44 Model performance:
2025-07-09 02:20:44   metrics/test.rmse:         147.37
2025-07-09 02:20:44   metrics/test.rmse_pcutoff:   4.87
2025-07-09 02:20:44   metrics/test.mAP:            0.00
2025-07-09 02:20:44   metrics/test.mAR:            0.00
2025-07-09 02:20:57 Epoch 81/200 (lr=0.0005), train loss 0.00317
2025-07-09 02:21:11 Epoch 82/200 (lr=0.0005), train loss 0.00348
2025-07-09 02:21:24 Epoch 83/200 (lr=0.0005), train loss 0.00310
2025-07-09 02:21:38 Epoch 84/200 (lr=0.0005), train loss 0.00339
2025-07-09 02:21:52 Epoch 85/200 (lr=0.0005), train loss 0.00275
2025-07-09 02:22:05 Epoch 86/200 (lr=0.0005), train loss 0.00231
2025-07-09 02:22:19 Epoch 87/200 (lr=0.0005), train loss 0.00313
2025-07-09 02:22:32 Epoch 88/200 (lr=0.0005), train loss 0.00338
2025-07-09 02:22:46 Epoch 89/200 (lr=0.0005), train loss 0.00304
2025-07-09 02:23:00 Training for epoch 90 done, starting evaluation
2025-07-09 02:23:02 Epoch 90/200 (lr=0.0001), train loss 0.00264, valid loss 0.00630
2025-07-09 02:23:02 Model performance:
2025-07-09 02:23:02   metrics/test.rmse:         103.95
2025-07-09 02:23:02   metrics/test.rmse_pcutoff:    nan
2025-07-09 02:23:02   metrics/test.mAP:            6.06
2025-07-09 02:23:02   metrics/test.mAR:           30.00
2025-07-09 02:23:16 Epoch 91/200 (lr=0.0001), train loss 0.00256
2025-07-09 02:23:29 Epoch 92/200 (lr=0.0001), train loss 0.00255
2025-07-09 02:23:43 Epoch 93/200 (lr=0.0001), train loss 0.00181
2025-07-09 02:23:56 Epoch 94/200 (lr=0.0001), train loss 0.00203
2025-07-09 02:24:10 Epoch 95/200 (lr=0.0001), train loss 0.00207
2025-07-09 02:24:24 Epoch 96/200 (lr=0.0001), train loss 0.00210
2025-07-09 02:24:38 Epoch 97/200 (lr=0.0001), train loss 0.00199
2025-07-09 02:24:52 Epoch 98/200 (lr=0.0001), train loss 0.00208
2025-07-09 02:25:05 Epoch 99/200 (lr=0.0001), train loss 0.00192
2025-07-09 02:25:19 Training for epoch 100 done, starting evaluation
2025-07-09 02:25:20 Epoch 100/200 (lr=0.0001), train loss 0.00172, valid loss 0.00584
2025-07-09 02:25:20 Model performance:
2025-07-09 02:25:20   metrics/test.rmse:           6.15
2025-07-09 02:25:20   metrics/test.rmse_pcutoff:   7.11
2025-07-09 02:25:20   metrics/test.mAP:           31.64
2025-07-09 02:25:20   metrics/test.mAR:           50.00
2025-07-09 02:25:35 Epoch 101/200 (lr=0.0001), train loss 0.00170
2025-07-09 02:25:48 Epoch 102/200 (lr=0.0001), train loss 0.00148
2025-07-09 02:26:02 Epoch 103/200 (lr=0.0001), train loss 0.00137
2025-07-09 02:26:16 Epoch 104/200 (lr=0.0001), train loss 0.00163
2025-07-09 02:26:30 Epoch 105/200 (lr=0.0001), train loss 0.00185
2025-07-09 02:26:44 Epoch 106/200 (lr=0.0001), train loss 0.00162
2025-07-09 02:26:58 Epoch 107/200 (lr=0.0001), train loss 0.00180
2025-07-09 02:27:11 Epoch 108/200 (lr=0.0001), train loss 0.00181
2025-07-09 02:27:25 Epoch 109/200 (lr=0.0001), train loss 0.00195
2025-07-09 02:27:39 Training for epoch 110 done, starting evaluation
2025-07-09 02:27:40 Epoch 110/200 (lr=0.0001), train loss 0.00172, valid loss 0.00670
2025-07-09 02:27:40 Model performance:
2025-07-09 02:27:40   metrics/test.rmse:         104.19
2025-07-09 02:27:40   metrics/test.rmse_pcutoff:   6.54
2025-07-09 02:27:40   metrics/test.mAP:            5.05
2025-07-09 02:27:40   metrics/test.mAR:           30.00
2025-07-09 02:27:53 Epoch 111/200 (lr=0.0001), train loss 0.00162
2025-07-09 02:28:07 Epoch 112/200 (lr=0.0001), train loss 0.00164
2025-07-09 02:28:20 Epoch 113/200 (lr=0.0001), train loss 0.00124
2025-07-09 02:28:34 Epoch 114/200 (lr=0.0001), train loss 0.00147
2025-07-09 02:28:48 Epoch 115/200 (lr=0.0001), train loss 0.00138
2025-07-09 02:29:01 Epoch 116/200 (lr=0.0001), train loss 0.00132
2025-07-09 02:29:15 Epoch 117/200 (lr=0.0001), train loss 0.00127
2025-07-09 02:29:29 Epoch 118/200 (lr=0.0001), train loss 0.00143
2025-07-09 02:29:43 Epoch 119/200 (lr=0.0001), train loss 0.00120
2025-07-09 02:29:56 Training for epoch 120 done, starting evaluation
2025-07-09 02:29:58 Epoch 120/200 (lr=1e-05), train loss 0.00181, valid loss 0.00553
2025-07-09 02:29:58 Model performance:
2025-07-09 02:29:58   metrics/test.rmse:           6.64
2025-07-09 02:29:58   metrics/test.rmse_pcutoff:   5.86
2025-07-09 02:29:58   metrics/test.mAP:           16.73
2025-07-09 02:29:58   metrics/test.mAR:           40.00
2025-07-09 02:30:11 Epoch 121/200 (lr=1e-05), train loss 0.00144
2025-07-09 02:30:25 Epoch 122/200 (lr=1e-05), train loss 0.00119
2025-07-09 02:30:38 Epoch 123/200 (lr=1e-05), train loss 0.00121
2025-07-09 02:30:52 Epoch 124/200 (lr=1e-05), train loss 0.00165
2025-07-09 02:31:06 Epoch 125/200 (lr=1e-05), train loss 0.00131
2025-07-09 02:31:20 Epoch 126/200 (lr=1e-05), train loss 0.00128
2025-07-09 02:31:33 Epoch 127/200 (lr=1e-05), train loss 0.00148
2025-07-09 02:31:47 Epoch 128/200 (lr=1e-05), train loss 0.00161
2025-07-09 02:32:01 Epoch 129/200 (lr=1e-05), train loss 0.00167
2025-07-09 02:32:14 Training for epoch 130 done, starting evaluation
2025-07-09 02:32:16 Epoch 130/200 (lr=1e-05), train loss 0.00137, valid loss 0.00575
2025-07-09 02:32:16 Model performance:
2025-07-09 02:32:16   metrics/test.rmse:           6.43
2025-07-09 02:32:16   metrics/test.rmse_pcutoff:   5.45
2025-07-09 02:32:16   metrics/test.mAP:           16.73
2025-07-09 02:32:16   metrics/test.mAR:           40.00
2025-07-09 02:32:30 Epoch 131/200 (lr=1e-05), train loss 0.00143
2025-07-09 02:32:44 Epoch 132/200 (lr=1e-05), train loss 0.00147
2025-07-09 02:32:57 Epoch 133/200 (lr=1e-05), train loss 0.00126
2025-07-09 02:33:11 Epoch 134/200 (lr=1e-05), train loss 0.00135
2025-07-09 02:33:24 Epoch 135/200 (lr=1e-05), train loss 0.00159
2025-07-09 02:33:38 Epoch 136/200 (lr=1e-05), train loss 0.00144
2025-07-09 02:33:52 Epoch 137/200 (lr=1e-05), train loss 0.00106
2025-07-09 02:34:05 Epoch 138/200 (lr=1e-05), train loss 0.00127
2025-07-09 02:34:19 Epoch 139/200 (lr=1e-05), train loss 0.00137
2025-07-09 02:34:32 Training for epoch 140 done, starting evaluation
2025-07-09 02:34:34 Epoch 140/200 (lr=1e-05), train loss 0.00119, valid loss 0.00583
2025-07-09 02:34:34 Model performance:
2025-07-09 02:34:34   metrics/test.rmse:           6.85
2025-07-09 02:34:34   metrics/test.rmse_pcutoff:   5.49
2025-07-09 02:34:34   metrics/test.mAP:           16.73
2025-07-09 02:34:34   metrics/test.mAR:           40.00
2025-07-09 02:34:47 Epoch 141/200 (lr=1e-05), train loss 0.00115
2025-07-09 02:35:01 Epoch 142/200 (lr=1e-05), train loss 0.00125
2025-07-09 02:35:14 Epoch 143/200 (lr=1e-05), train loss 0.00132
2025-07-09 02:35:29 Epoch 144/200 (lr=1e-05), train loss 0.00126
2025-07-09 02:35:43 Epoch 145/200 (lr=1e-05), train loss 0.00116
2025-07-09 02:35:56 Epoch 146/200 (lr=1e-05), train loss 0.00135
2025-07-09 02:36:10 Epoch 147/200 (lr=1e-05), train loss 0.00121
2025-07-09 02:36:24 Epoch 148/200 (lr=1e-05), train loss 0.00125
2025-07-09 02:36:37 Epoch 149/200 (lr=1e-05), train loss 0.00148
2025-07-09 02:36:50 Training for epoch 150 done, starting evaluation
2025-07-09 02:36:52 Epoch 150/200 (lr=1e-05), train loss 0.00126, valid loss 0.00590
2025-07-09 02:36:52 Model performance:
2025-07-09 02:36:52   metrics/test.rmse:          45.74
2025-07-09 02:36:52   metrics/test.rmse_pcutoff:   5.63
2025-07-09 02:36:52   metrics/test.mAP:            4.49
2025-07-09 02:36:52   metrics/test.mAR:           26.67
2025-07-09 02:37:06 Epoch 151/200 (lr=1e-05), train loss 0.00128
2025-07-09 02:37:19 Epoch 152/200 (lr=1e-05), train loss 0.00128
2025-07-09 02:37:33 Epoch 153/200 (lr=1e-05), train loss 0.00133
2025-07-09 02:37:46 Epoch 154/200 (lr=1e-05), train loss 0.00144
2025-07-09 02:38:00 Epoch 155/200 (lr=1e-05), train loss 0.00131
2025-07-09 02:38:14 Epoch 156/200 (lr=1e-05), train loss 0.00116
2025-07-09 02:38:27 Epoch 157/200 (lr=1e-05), train loss 0.00140
2025-07-09 02:38:41 Epoch 158/200 (lr=1e-05), train loss 0.00142
2025-07-09 02:38:55 Epoch 159/200 (lr=1e-05), train loss 0.00124
2025-07-09 02:39:09 Training for epoch 160 done, starting evaluation
2025-07-09 02:39:10 Epoch 160/200 (lr=1e-05), train loss 0.00119, valid loss 0.00594
2025-07-09 02:39:10 Model performance:
2025-07-09 02:39:10   metrics/test.rmse:           7.37
2025-07-09 02:39:10   metrics/test.rmse_pcutoff:   5.58
2025-07-09 02:39:10   metrics/test.mAP:           20.07
2025-07-09 02:39:10   metrics/test.mAR:           40.00
2025-07-09 02:39:24 Epoch 161/200 (lr=1e-05), train loss 0.00130
2025-07-09 02:39:37 Epoch 162/200 (lr=1e-05), train loss 0.00160
2025-07-09 02:39:51 Epoch 163/200 (lr=1e-05), train loss 0.00142
2025-07-09 02:40:05 Epoch 164/200 (lr=1e-05), train loss 0.00131
2025-07-09 02:40:18 Epoch 165/200 (lr=1e-05), train loss 0.00137
2025-07-09 02:40:32 Epoch 166/200 (lr=1e-05), train loss 0.00139
2025-07-09 02:40:46 Epoch 167/200 (lr=1e-05), train loss 0.00156
2025-07-09 02:40:59 Epoch 168/200 (lr=1e-05), train loss 0.00122
2025-07-09 02:41:13 Epoch 169/200 (lr=1e-05), train loss 0.00147
2025-07-09 02:41:26 Training for epoch 170 done, starting evaluation
2025-07-09 02:41:28 Epoch 170/200 (lr=1e-05), train loss 0.00137, valid loss 0.00593
2025-07-09 02:41:28 Model performance:
2025-07-09 02:41:28   metrics/test.rmse:           7.45
2025-07-09 02:41:28   metrics/test.rmse_pcutoff:   5.50
2025-07-09 02:41:28   metrics/test.mAP:           16.17
2025-07-09 02:41:28   metrics/test.mAR:           36.67
2025-07-09 02:41:41 Epoch 171/200 (lr=1e-05), train loss 0.00168
2025-07-09 02:41:56 Epoch 172/200 (lr=1e-05), train loss 0.00154
2025-07-09 02:42:09 Epoch 173/200 (lr=1e-05), train loss 0.00112
2025-07-09 02:42:23 Epoch 174/200 (lr=1e-05), train loss 0.00118
2025-07-09 02:42:37 Epoch 175/200 (lr=1e-05), train loss 0.00113
2025-07-09 02:42:51 Epoch 176/200 (lr=1e-05), train loss 0.00112
2025-07-09 02:43:04 Epoch 177/200 (lr=1e-05), train loss 0.00123
2025-07-09 02:43:17 Epoch 178/200 (lr=1e-05), train loss 0.00115
2025-07-09 02:43:31 Epoch 179/200 (lr=1e-05), train loss 0.00139
2025-07-09 02:43:45 Training for epoch 180 done, starting evaluation
2025-07-09 02:43:53 Epoch 180/200 (lr=1e-05), train loss 0.00127, valid loss 0.00606
2025-07-09 02:43:53 Model performance:
2025-07-09 02:43:53   metrics/test.rmse:           7.49
2025-07-09 02:43:53   metrics/test.rmse_pcutoff:   5.50
2025-07-09 02:43:53   metrics/test.mAP:           16.17
2025-07-09 02:43:53   metrics/test.mAR:           36.67
2025-07-09 02:44:07 Epoch 181/200 (lr=1e-05), train loss 0.00131
2025-07-09 02:44:21 Epoch 182/200 (lr=1e-05), train loss 0.00144
2025-07-09 02:44:35 Epoch 183/200 (lr=1e-05), train loss 0.00106
2025-07-09 02:44:48 Epoch 184/200 (lr=1e-05), train loss 0.00115
2025-07-09 02:45:09 Epoch 185/200 (lr=1e-05), train loss 0.00154
2025-07-09 02:45:23 Epoch 186/200 (lr=1e-05), train loss 0.00163
2025-07-09 02:45:36 Epoch 187/200 (lr=1e-05), train loss 0.00150
2025-07-09 02:45:50 Epoch 188/200 (lr=1e-05), train loss 0.00100
2025-07-09 02:46:04 Epoch 189/200 (lr=1e-05), train loss 0.00122
2025-07-09 02:46:17 Training for epoch 190 done, starting evaluation
2025-07-09 02:46:25 Epoch 190/200 (lr=1e-05), train loss 0.00137, valid loss 0.00599
2025-07-09 02:46:25 Model performance:
2025-07-09 02:46:25   metrics/test.rmse:           7.26
2025-07-09 02:46:25   metrics/test.rmse_pcutoff:   5.26
2025-07-09 02:46:25   metrics/test.mAP:           20.07
2025-07-09 02:46:25   metrics/test.mAR:           40.00
2025-07-09 02:46:39 Epoch 191/200 (lr=1e-05), train loss 0.00114
2025-07-09 02:46:52 Epoch 192/200 (lr=1e-05), train loss 0.00123
2025-07-09 02:47:06 Epoch 193/200 (lr=1e-05), train loss 0.00113
2025-07-09 02:47:20 Epoch 194/200 (lr=1e-05), train loss 0.00114
2025-07-09 02:47:39 Epoch 195/200 (lr=1e-05), train loss 0.00118
2025-07-09 02:47:53 Epoch 196/200 (lr=1e-05), train loss 0.00139
2025-07-09 02:48:08 Epoch 197/200 (lr=1e-05), train loss 0.00104
2025-07-09 02:48:21 Epoch 198/200 (lr=1e-05), train loss 0.00142
2025-07-09 02:48:35 Epoch 199/200 (lr=1e-05), train loss 0.00135
2025-07-09 02:48:49 Training for epoch 200 done, starting evaluation
2025-07-09 02:48:55 Epoch 200/200 (lr=1e-05), train loss 0.00103, valid loss 0.00596
2025-07-09 02:48:55 Model performance:
2025-07-09 02:48:55   metrics/test.rmse:           7.53
2025-07-09 02:48:55   metrics/test.rmse_pcutoff:   5.23
2025-07-09 02:48:55   metrics/test.mAP:           16.17
2025-07-09 02:48:55   metrics/test.mAR:           36.67
2025-07-28 14:09:05 Training with configuration:
2025-07-28 14:09:05 data:
2025-07-28 14:09:05   bbox_margin: 20
2025-07-28 14:09:05   colormode: RGB
2025-07-28 14:09:05   inference:
2025-07-28 14:09:05     normalize_images: True
2025-07-28 14:09:05   train:
2025-07-28 14:09:05     affine:
2025-07-28 14:09:05       p: 0.5
2025-07-28 14:09:05       rotation: 30
2025-07-28 14:09:05       scaling: [0.5, 1.25]
2025-07-28 14:09:05       translation: 0
2025-07-28 14:09:05     crop_sampling:
2025-07-28 14:09:05       width: 448
2025-07-28 14:09:05       height: 448
2025-07-28 14:09:05       max_shift: 0.1
2025-07-28 14:09:05       method: hybrid
2025-07-28 14:09:05     gaussian_noise: 12.75
2025-07-28 14:09:05     motion_blur: True
2025-07-28 14:09:05     normalize_images: True
2025-07-28 14:09:05 device: auto
2025-07-28 14:09:05 metadata:
2025-07-28 14:09:05   project_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12
2025-07-28 14:09:05   pose_config_path: /content/drive/My Drive/pigs-heart-rate-dlc-2025-05-12/dlc-models-pytorch/iteration-0/pigs-heart-rateMay12-trainset95shuffle1/train/pytorch_config.yaml
2025-07-28 14:09:05   bodyparts: ['L ear base', 'R ear base', 'Mid snout']
2025-07-28 14:09:05   unique_bodyparts: []
2025-07-28 14:09:05   individuals: ['animal']
2025-07-28 14:09:05   with_identity: None
2025-07-28 14:09:05 method: bu
2025-07-28 14:09:05 model:
2025-07-28 14:09:05   backbone:
2025-07-28 14:09:05     type: ResNet
2025-07-28 14:09:05     model_name: resnet50_gn
2025-07-28 14:09:05     output_stride: 16
2025-07-28 14:09:05     freeze_bn_stats: False
2025-07-28 14:09:05     freeze_bn_weights: False
2025-07-28 14:09:05   backbone_output_channels: 2048
2025-07-28 14:09:05   heads:
2025-07-28 14:09:05     bodypart:
2025-07-28 14:09:05       type: HeatmapHead
2025-07-28 14:09:05       weight_init: normal
2025-07-28 14:09:05       predictor:
2025-07-28 14:09:05         type: HeatmapPredictor
2025-07-28 14:09:05         apply_sigmoid: False
2025-07-28 14:09:05         clip_scores: True
2025-07-28 14:09:05         location_refinement: True
2025-07-28 14:09:05         locref_std: 7.2801
2025-07-28 14:09:05       target_generator:
2025-07-28 14:09:05         type: HeatmapGaussianGenerator
2025-07-28 14:09:05         num_heatmaps: 3
2025-07-28 14:09:05         pos_dist_thresh: 17
2025-07-28 14:09:05         heatmap_mode: KEYPOINT
2025-07-28 14:09:05         gradient_masking: False
2025-07-28 14:09:05         generate_locref: True
2025-07-28 14:09:05         locref_std: 7.2801
2025-07-28 14:09:05       criterion:
2025-07-28 14:09:05         heatmap:
2025-07-28 14:09:05           type: WeightedMSECriterion
2025-07-28 14:09:05           weight: 1.0
2025-07-28 14:09:05         locref:
2025-07-28 14:09:05           type: WeightedHuberCriterion
2025-07-28 14:09:05           weight: 0.05
2025-07-28 14:09:05       heatmap_config:
2025-07-28 14:09:05         channels: [2048, 3]
2025-07-28 14:09:05         kernel_size: [3]
2025-07-28 14:09:05         strides: [2]
2025-07-28 14:09:05       locref_config:
2025-07-28 14:09:05         channels: [2048, 6]
2025-07-28 14:09:05         kernel_size: [3]
2025-07-28 14:09:05         strides: [2]
2025-07-28 14:09:05 net_type: resnet_50
2025-07-28 14:09:05 runner:
2025-07-28 14:09:05   type: PoseTrainingRunner
2025-07-28 14:09:05   gpus: None
2025-07-28 14:09:05   key_metric: test.mAP
2025-07-28 14:09:05   key_metric_asc: True
2025-07-28 14:09:05   eval_interval: 10
2025-07-28 14:09:05   optimizer:
2025-07-28 14:09:05     type: AdamW
2025-07-28 14:09:05     params:
2025-07-28 14:09:05       lr: 0.0005
2025-07-28 14:09:05   scheduler:
2025-07-28 14:09:05     type: LRListScheduler
2025-07-28 14:09:05     params:
2025-07-28 14:09:05       lr_list: [[0.0001], [1e-05]]
2025-07-28 14:09:05       milestones: [90, 120]
2025-07-28 14:09:05   snapshots:
2025-07-28 14:09:05     max_snapshots: 5
2025-07-28 14:09:05     save_epochs: 5
2025-07-28 14:09:05     save_optimizer_state: False
2025-07-28 14:09:05 train_settings:
2025-07-28 14:09:05   batch_size: 8
2025-07-28 14:09:05   dataloader_workers: 0
2025-07-28 14:09:05   dataloader_pin_memory: False
2025-07-28 14:09:05   display_iters: 500
2025-07-28 14:09:05   epochs: 200
2025-07-28 14:09:05   seed: 42
2025-07-28 14:09:05 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-07-28 14:09:06 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-07-28 14:09:07 Data Transforms:
2025-07-28 14:09:07   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-07-28 14:09:07   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-07-28 14:09:08 Using 110 images and 6 for testing
2025-07-28 14:09:08 
Starting pose model training...
--------------------------------------------------
2025-07-28 14:09:24 Epoch 1/200 (lr=0.0005), train loss 0.01563
2025-07-28 14:09:37 Epoch 2/200 (lr=0.0005), train loss 0.01489
2025-07-28 14:09:50 Epoch 3/200 (lr=0.0005), train loss 0.01476
2025-07-28 14:10:04 Epoch 4/200 (lr=0.0005), train loss 0.01475
2025-07-28 14:10:17 Epoch 5/200 (lr=0.0005), train loss 0.01471
2025-07-28 14:10:30 Epoch 6/200 (lr=0.0005), train loss 0.01464
2025-07-28 14:10:44 Epoch 7/200 (lr=0.0005), train loss 0.01431
2025-07-28 14:10:57 Epoch 8/200 (lr=0.0005), train loss 0.01456
2025-07-28 14:11:10 Epoch 9/200 (lr=0.0005), train loss 0.01467
2025-07-28 14:11:23 Training for epoch 10 done, starting evaluation
2025-07-28 14:11:25 Epoch 10/200 (lr=0.0005), train loss 0.01448, valid loss 0.01408
2025-07-28 14:11:25 Model performance:
2025-07-28 14:11:25   metrics/test.rmse:         148.17
2025-07-28 14:11:25   metrics/test.rmse_pcutoff:    nan
2025-07-28 14:11:25   metrics/test.mAP:            0.00
2025-07-28 14:11:25   metrics/test.mAR:            0.00
2025-07-28 14:11:38 Epoch 11/200 (lr=0.0005), train loss 0.01443
2025-07-28 14:11:52 Epoch 12/200 (lr=0.0005), train loss 0.01345
2025-07-28 14:12:05 Epoch 13/200 (lr=0.0005), train loss 0.01373
2025-07-28 14:12:18 Epoch 14/200 (lr=0.0005), train loss 0.01204
2025-07-28 14:12:32 Epoch 15/200 (lr=0.0005), train loss 0.01279
2025-07-28 14:12:45 Epoch 16/200 (lr=0.0005), train loss 0.01149
2025-07-28 14:12:59 Epoch 17/200 (lr=0.0005), train loss 0.01113
2025-07-28 14:13:12 Epoch 18/200 (lr=0.0005), train loss 0.01067
2025-07-28 14:13:26 Epoch 19/200 (lr=0.0005), train loss 0.00980
2025-07-28 14:13:39 Training for epoch 20 done, starting evaluation
2025-07-28 14:13:41 Epoch 20/200 (lr=0.0005), train loss 0.00978, valid loss 0.00677
2025-07-28 14:13:41 Model performance:
2025-07-28 14:13:41   metrics/test.rmse:          15.16
2025-07-28 14:13:41   metrics/test.rmse_pcutoff:    nan
2025-07-28 14:13:41   metrics/test.mAP:           16.83
2025-07-28 14:13:41   metrics/test.mAR:           16.67
2025-07-28 14:13:54 Epoch 21/200 (lr=0.0005), train loss 0.00836
2025-07-28 14:14:08 Epoch 22/200 (lr=0.0005), train loss 0.00860
2025-07-28 14:14:22 Epoch 23/200 (lr=0.0005), train loss 0.00777
2025-07-28 14:14:35 Epoch 24/200 (lr=0.0005), train loss 0.00805
2025-07-28 14:14:49 Epoch 25/200 (lr=0.0005), train loss 0.00698
2025-07-28 14:15:03 Epoch 26/200 (lr=0.0005), train loss 0.00768
2025-07-28 14:15:16 Epoch 27/200 (lr=0.0005), train loss 0.00798
2025-07-28 14:15:30 Epoch 28/200 (lr=0.0005), train loss 0.00729
2025-07-28 14:15:43 Epoch 29/200 (lr=0.0005), train loss 0.00693
2025-07-28 14:15:57 Training for epoch 30 done, starting evaluation
2025-07-28 14:15:58 Epoch 30/200 (lr=0.0005), train loss 0.00656, valid loss 0.00774
2025-07-28 14:15:58 Model performance:
2025-07-28 14:15:58   metrics/test.rmse:         298.03
2025-07-28 14:15:58   metrics/test.rmse_pcutoff:    nan
2025-07-28 14:15:58   metrics/test.mAP:            0.00
2025-07-28 14:15:58   metrics/test.mAR:            0.00
2025-07-28 14:16:12 Epoch 31/200 (lr=0.0005), train loss 0.00637
2025-07-28 14:16:25 Epoch 32/200 (lr=0.0005), train loss 0.00579
2025-07-28 14:16:38 Epoch 33/200 (lr=0.0005), train loss 0.00613
2025-07-28 14:16:52 Epoch 34/200 (lr=0.0005), train loss 0.00627
2025-07-28 14:17:06 Epoch 35/200 (lr=0.0005), train loss 0.00549
2025-07-28 14:17:19 Epoch 36/200 (lr=0.0005), train loss 0.00637
2025-07-28 14:17:33 Epoch 37/200 (lr=0.0005), train loss 0.00536
2025-07-28 14:17:47 Epoch 38/200 (lr=0.0005), train loss 0.00594
2025-07-28 14:18:00 Epoch 39/200 (lr=0.0005), train loss 0.00548
2025-07-28 14:18:14 Training for epoch 40 done, starting evaluation
2025-07-28 14:18:15 Epoch 40/200 (lr=0.0005), train loss 0.00525, valid loss 0.00425
2025-07-28 14:18:15 Model performance:
2025-07-28 14:18:15   metrics/test.rmse:          46.89
2025-07-28 14:18:15   metrics/test.rmse_pcutoff:   5.65
2025-07-28 14:18:15   metrics/test.mAP:           23.56
2025-07-28 14:18:15   metrics/test.mAR:           23.33
2025-07-28 14:18:29 Epoch 41/200 (lr=0.0005), train loss 0.00507
2025-07-28 14:18:43 Epoch 42/200 (lr=0.0005), train loss 0.00501
2025-07-28 14:18:56 Epoch 43/200 (lr=0.0005), train loss 0.00488
2025-07-28 14:19:10 Epoch 44/200 (lr=0.0005), train loss 0.00516
2025-07-28 14:19:24 Epoch 45/200 (lr=0.0005), train loss 0.00517
2025-07-28 14:19:38 Epoch 46/200 (lr=0.0005), train loss 0.00486
2025-07-28 14:19:52 Epoch 47/200 (lr=0.0005), train loss 0.00447
2025-07-28 14:20:05 Epoch 48/200 (lr=0.0005), train loss 0.00422
2025-07-28 14:20:19 Epoch 49/200 (lr=0.0005), train loss 0.00499
2025-07-28 14:20:32 Training for epoch 50 done, starting evaluation
2025-07-28 14:20:34 Epoch 50/200 (lr=0.0005), train loss 0.00506, valid loss 0.00541
2025-07-28 14:20:34 Model performance:
2025-07-28 14:20:34   metrics/test.rmse:         114.38
2025-07-28 14:20:34   metrics/test.rmse_pcutoff:  10.21
2025-07-28 14:20:34   metrics/test.mAP:           16.83
2025-07-28 14:20:34   metrics/test.mAR:           16.67
2025-07-28 14:20:48 Epoch 51/200 (lr=0.0005), train loss 0.00495
2025-07-28 14:21:01 Epoch 52/200 (lr=0.0005), train loss 0.00504
2025-07-28 14:21:15 Epoch 53/200 (lr=0.0005), train loss 0.00467
2025-07-28 14:21:29 Epoch 54/200 (lr=0.0005), train loss 0.00460
2025-07-28 14:21:43 Epoch 55/200 (lr=0.0005), train loss 0.00380
2025-07-28 14:21:57 Epoch 56/200 (lr=0.0005), train loss 0.00386
2025-07-28 14:22:10 Epoch 57/200 (lr=0.0005), train loss 0.00446
2025-07-28 14:22:24 Epoch 58/200 (lr=0.0005), train loss 0.00390
2025-07-28 14:22:38 Epoch 59/200 (lr=0.0005), train loss 0.00347
2025-07-28 14:22:52 Training for epoch 60 done, starting evaluation
2025-07-28 14:22:53 Epoch 60/200 (lr=0.0005), train loss 0.00395, valid loss 0.00470
2025-07-28 14:22:53 Model performance:
2025-07-28 14:22:53   metrics/test.rmse:         161.74
2025-07-28 14:22:53   metrics/test.rmse_pcutoff:   2.27
2025-07-28 14:22:53   metrics/test.mAP:           23.56
2025-07-28 14:22:53   metrics/test.mAR:           23.33
2025-07-28 14:23:07 Epoch 61/200 (lr=0.0005), train loss 0.00339
2025-07-28 14:23:21 Epoch 62/200 (lr=0.0005), train loss 0.00421
2025-07-28 14:23:35 Epoch 63/200 (lr=0.0005), train loss 0.00375
2025-07-28 14:23:48 Epoch 64/200 (lr=0.0005), train loss 0.00344
2025-07-28 14:24:02 Epoch 65/200 (lr=0.0005), train loss 0.00384
2025-07-28 14:24:15 Epoch 66/200 (lr=0.0005), train loss 0.00300
2025-07-28 14:24:29 Epoch 67/200 (lr=0.0005), train loss 0.00441
2025-07-28 14:24:43 Epoch 68/200 (lr=0.0005), train loss 0.00408
2025-07-28 14:24:57 Epoch 69/200 (lr=0.0005), train loss 0.00363
2025-07-28 14:25:10 Training for epoch 70 done, starting evaluation
2025-07-28 14:25:11 Epoch 70/200 (lr=0.0005), train loss 0.00323, valid loss 0.00480
2025-07-28 14:25:11 Model performance:
2025-07-28 14:25:11   metrics/test.rmse:          23.07
2025-07-28 14:25:11   metrics/test.rmse_pcutoff:   4.78
2025-07-28 14:25:11   metrics/test.mAP:           19.41
2025-07-28 14:25:11   metrics/test.mAR:           46.67
2025-07-28 14:25:25 Epoch 71/200 (lr=0.0005), train loss 0.00368
2025-07-28 14:25:38 Epoch 72/200 (lr=0.0005), train loss 0.00378
2025-07-28 14:25:52 Epoch 73/200 (lr=0.0005), train loss 0.00345
2025-07-28 14:26:05 Epoch 74/200 (lr=0.0005), train loss 0.00313
2025-07-28 14:26:19 Epoch 75/200 (lr=0.0005), train loss 0.00370
2025-07-28 14:26:32 Epoch 76/200 (lr=0.0005), train loss 0.00334
2025-07-28 14:26:46 Epoch 77/200 (lr=0.0005), train loss 0.00342
2025-07-28 14:26:59 Epoch 78/200 (lr=0.0005), train loss 0.00268
2025-07-28 14:27:13 Epoch 79/200 (lr=0.0005), train loss 0.00319
2025-07-28 14:27:30 Training for epoch 80 done, starting evaluation
2025-07-28 14:27:31 Epoch 80/200 (lr=0.0005), train loss 0.00330, valid loss 0.00379
2025-07-28 14:27:31 Model performance:
2025-07-28 14:27:31   metrics/test.rmse:          36.01
2025-07-28 14:27:31   metrics/test.rmse_pcutoff:   3.26
2025-07-28 14:27:31   metrics/test.mAP:           39.45
2025-07-28 14:27:31   metrics/test.mAR:           53.33
2025-07-28 14:27:45 Epoch 81/200 (lr=0.0005), train loss 0.00363
2025-07-28 14:27:59 Epoch 82/200 (lr=0.0005), train loss 0.00342
2025-07-28 14:28:12 Epoch 83/200 (lr=0.0005), train loss 0.00317
2025-07-28 14:28:26 Epoch 84/200 (lr=0.0005), train loss 0.00289
2025-07-28 14:28:40 Epoch 85/200 (lr=0.0005), train loss 0.00278
2025-07-28 14:28:53 Epoch 86/200 (lr=0.0005), train loss 0.00286
2025-07-28 14:29:07 Epoch 87/200 (lr=0.0005), train loss 0.00355
2025-07-28 14:29:25 Epoch 88/200 (lr=0.0005), train loss 0.00327
2025-07-28 14:29:39 Epoch 89/200 (lr=0.0005), train loss 0.00330
2025-07-28 14:29:52 Training for epoch 90 done, starting evaluation
2025-07-28 14:29:53 Epoch 90/200 (lr=0.0001), train loss 0.00281, valid loss 0.00385
2025-07-28 14:29:53 Model performance:
2025-07-28 14:29:53   metrics/test.rmse:           4.26
2025-07-28 14:29:53   metrics/test.rmse_pcutoff:   2.98
2025-07-28 14:29:53   metrics/test.mAP:           32.48
2025-07-28 14:29:53   metrics/test.mAR:           56.67
2025-07-28 14:30:07 Epoch 91/200 (lr=0.0001), train loss 0.00283
2025-07-28 14:30:21 Epoch 92/200 (lr=0.0001), train loss 0.00241
2025-07-28 14:30:36 Epoch 93/200 (lr=0.0001), train loss 0.00216
2025-07-28 14:30:49 Epoch 94/200 (lr=0.0001), train loss 0.00223
2025-07-28 14:31:03 Epoch 95/200 (lr=0.0001), train loss 0.00221
2025-07-28 14:31:17 Epoch 96/200 (lr=0.0001), train loss 0.00276
2025-07-28 14:31:31 Epoch 97/200 (lr=0.0001), train loss 0.00216
2025-07-28 14:31:44 Epoch 98/200 (lr=0.0001), train loss 0.00190
2025-07-28 14:31:58 Epoch 99/200 (lr=0.0001), train loss 0.00214
2025-07-28 14:32:12 Training for epoch 100 done, starting evaluation
2025-07-28 14:32:13 Epoch 100/200 (lr=0.0001), train loss 0.00185, valid loss 0.00400
2025-07-28 14:32:13 Model performance:
2025-07-28 14:32:13   metrics/test.rmse:          16.66
2025-07-28 14:32:13   metrics/test.rmse_pcutoff:   3.61
2025-07-28 14:32:13   metrics/test.mAP:           45.84
2025-07-28 14:32:13   metrics/test.mAR:           63.33
2025-07-28 14:32:27 Epoch 101/200 (lr=0.0001), train loss 0.00185
2025-07-28 14:32:41 Epoch 102/200 (lr=0.0001), train loss 0.00151
2025-07-28 14:32:54 Epoch 103/200 (lr=0.0001), train loss 0.00194
2025-07-28 14:33:08 Epoch 104/200 (lr=0.0001), train loss 0.00193
2025-07-28 14:33:22 Epoch 105/200 (lr=0.0001), train loss 0.00189
2025-07-28 14:33:35 Epoch 106/200 (lr=0.0001), train loss 0.00179
2025-07-28 14:33:49 Epoch 107/200 (lr=0.0001), train loss 0.00214
2025-07-28 14:34:03 Epoch 108/200 (lr=0.0001), train loss 0.00186
2025-07-28 14:34:17 Epoch 109/200 (lr=0.0001), train loss 0.00178
2025-07-28 14:34:31 Training for epoch 110 done, starting evaluation
2025-07-28 14:34:32 Epoch 110/200 (lr=0.0001), train loss 0.00163, valid loss 0.00368
2025-07-28 14:34:32 Model performance:
2025-07-28 14:34:32   metrics/test.rmse:           4.01
2025-07-28 14:34:32   metrics/test.rmse_pcutoff:   2.53
2025-07-28 14:34:32   metrics/test.mAP:           48.37
2025-07-28 14:34:32   metrics/test.mAR:           63.33
2025-07-28 14:34:46 Epoch 111/200 (lr=0.0001), train loss 0.00220
2025-07-28 14:35:00 Epoch 112/200 (lr=0.0001), train loss 0.00184
2025-07-28 14:35:13 Epoch 113/200 (lr=0.0001), train loss 0.00139
2025-07-28 14:35:27 Epoch 114/200 (lr=0.0001), train loss 0.00134
2025-07-28 14:35:41 Epoch 115/200 (lr=0.0001), train loss 0.00154
2025-07-28 14:35:55 Epoch 116/200 (lr=0.0001), train loss 0.00152
2025-07-28 14:36:09 Epoch 117/200 (lr=0.0001), train loss 0.00148
2025-07-28 14:36:23 Epoch 118/200 (lr=0.0001), train loss 0.00142
2025-07-28 14:36:36 Epoch 119/200 (lr=0.0001), train loss 0.00132
2025-07-28 14:36:50 Training for epoch 120 done, starting evaluation
2025-07-28 14:36:51 Epoch 120/200 (lr=1e-05), train loss 0.00197, valid loss 0.00393
2025-07-28 14:36:51 Model performance:
2025-07-28 14:36:51   metrics/test.rmse:           4.16
2025-07-28 14:36:51   metrics/test.rmse_pcutoff:   2.93
2025-07-28 14:36:51   metrics/test.mAP:           48.37
2025-07-28 14:36:51   metrics/test.mAR:           63.33
2025-07-28 14:37:05 Epoch 121/200 (lr=1e-05), train loss 0.00150
2025-07-28 14:37:18 Epoch 122/200 (lr=1e-05), train loss 0.00120
2025-07-28 14:37:32 Epoch 123/200 (lr=1e-05), train loss 0.00140
2025-07-28 14:37:46 Epoch 124/200 (lr=1e-05), train loss 0.00170
2025-07-28 14:38:00 Epoch 125/200 (lr=1e-05), train loss 0.00135
2025-07-28 14:38:14 Epoch 126/200 (lr=1e-05), train loss 0.00157
2025-07-28 14:38:28 Epoch 127/200 (lr=1e-05), train loss 0.00153
2025-07-28 14:38:42 Epoch 128/200 (lr=1e-05), train loss 0.00146
2025-07-28 14:38:56 Epoch 129/200 (lr=1e-05), train loss 0.00125
2025-07-28 14:39:10 Training for epoch 130 done, starting evaluation
2025-07-28 14:39:11 Epoch 130/200 (lr=1e-05), train loss 0.00175, valid loss 0.00379
2025-07-28 14:39:11 Model performance:
2025-07-28 14:39:11   metrics/test.rmse:           4.12
2025-07-28 14:39:11   metrics/test.rmse_pcutoff:   2.70
2025-07-28 14:39:11   metrics/test.mAP:           48.37
2025-07-28 14:39:11   metrics/test.mAR:           63.33
2025-07-28 14:39:25 Epoch 131/200 (lr=1e-05), train loss 0.00133
2025-07-28 14:39:39 Epoch 132/200 (lr=1e-05), train loss 0.00146
2025-07-28 14:39:53 Epoch 133/200 (lr=1e-05), train loss 0.00157
2025-07-28 14:40:06 Epoch 134/200 (lr=1e-05), train loss 0.00136
2025-07-28 14:40:20 Epoch 135/200 (lr=1e-05), train loss 0.00178
2025-07-28 14:40:34 Epoch 136/200 (lr=1e-05), train loss 0.00139
2025-07-28 14:40:48 Epoch 137/200 (lr=1e-05), train loss 0.00145
2025-07-28 14:41:02 Epoch 138/200 (lr=1e-05), train loss 0.00145
2025-07-28 14:41:16 Epoch 139/200 (lr=1e-05), train loss 0.00137
2025-07-28 14:41:30 Training for epoch 140 done, starting evaluation
2025-07-28 14:41:31 Epoch 140/200 (lr=1e-05), train loss 0.00137, valid loss 0.00377
2025-07-28 14:41:31 Model performance:
2025-07-28 14:41:31   metrics/test.rmse:           4.28
2025-07-28 14:41:31   metrics/test.rmse_pcutoff:   2.94
2025-07-28 14:41:31   metrics/test.mAP:           48.37
2025-07-28 14:41:31   metrics/test.mAR:           63.33
2025-07-28 14:41:45 Epoch 141/200 (lr=1e-05), train loss 0.00135
2025-07-28 14:41:59 Epoch 142/200 (lr=1e-05), train loss 0.00117
2025-07-28 14:42:13 Epoch 143/200 (lr=1e-05), train loss 0.00126
2025-07-28 14:42:27 Epoch 144/200 (lr=1e-05), train loss 0.00133
2025-07-28 14:42:41 Epoch 145/200 (lr=1e-05), train loss 0.00152
2025-07-28 14:42:55 Epoch 146/200 (lr=1e-05), train loss 0.00148
2025-07-28 14:43:09 Epoch 147/200 (lr=1e-05), train loss 0.00164
2025-07-28 14:43:22 Epoch 148/200 (lr=1e-05), train loss 0.00116
2025-07-28 14:43:36 Epoch 149/200 (lr=1e-05), train loss 0.00130
2025-07-28 14:43:49 Training for epoch 150 done, starting evaluation
2025-07-28 14:43:51 Epoch 150/200 (lr=1e-05), train loss 0.00132, valid loss 0.00373
2025-07-28 14:43:51 Model performance:
2025-07-28 14:43:51   metrics/test.rmse:           4.22
2025-07-28 14:43:51   metrics/test.rmse_pcutoff:   2.85
2025-07-28 14:43:51   metrics/test.mAP:           48.37
2025-07-28 14:43:51   metrics/test.mAR:           63.33
2025-07-28 14:44:05 Epoch 151/200 (lr=1e-05), train loss 0.00121
2025-07-28 14:44:18 Epoch 152/200 (lr=1e-05), train loss 0.00144
2025-07-28 14:44:32 Epoch 153/200 (lr=1e-05), train loss 0.00165
2025-07-28 14:44:45 Epoch 154/200 (lr=1e-05), train loss 0.00120
2025-07-28 14:44:59 Epoch 155/200 (lr=1e-05), train loss 0.00139
2025-07-28 14:45:13 Epoch 156/200 (lr=1e-05), train loss 0.00126
2025-07-28 14:45:26 Epoch 157/200 (lr=1e-05), train loss 0.00131
2025-07-28 14:45:40 Epoch 158/200 (lr=1e-05), train loss 0.00161
2025-07-28 14:45:53 Epoch 159/200 (lr=1e-05), train loss 0.00130
2025-07-28 14:46:07 Training for epoch 160 done, starting evaluation
2025-07-28 14:46:09 Epoch 160/200 (lr=1e-05), train loss 0.00137, valid loss 0.00362
2025-07-28 14:46:09 Model performance:
2025-07-28 14:46:09   metrics/test.rmse:           4.15
2025-07-28 14:46:09   metrics/test.rmse_pcutoff:   2.75
2025-07-28 14:46:09   metrics/test.mAP:           48.37
2025-07-28 14:46:09   metrics/test.mAR:           63.33
2025-07-28 14:46:22 Epoch 161/200 (lr=1e-05), train loss 0.00127
2025-07-28 14:46:36 Epoch 162/200 (lr=1e-05), train loss 0.00188
2025-07-28 14:46:50 Epoch 163/200 (lr=1e-05), train loss 0.00148
2025-07-28 14:47:03 Epoch 164/200 (lr=1e-05), train loss 0.00142
2025-07-28 14:47:17 Epoch 165/200 (lr=1e-05), train loss 0.00131
2025-07-28 14:47:30 Epoch 166/200 (lr=1e-05), train loss 0.00127
2025-07-28 14:47:44 Epoch 167/200 (lr=1e-05), train loss 0.00151
2025-07-28 14:47:58 Epoch 168/200 (lr=1e-05), train loss 0.00117
2025-07-28 14:48:11 Epoch 169/200 (lr=1e-05), train loss 0.00142
2025-07-28 14:48:25 Training for epoch 170 done, starting evaluation
2025-07-28 14:48:26 Epoch 170/200 (lr=1e-05), train loss 0.00114, valid loss 0.00371
2025-07-28 14:48:26 Model performance:
2025-07-28 14:48:26   metrics/test.rmse:           4.21
2025-07-28 14:48:26   metrics/test.rmse_pcutoff:   2.68
2025-07-28 14:48:26   metrics/test.mAP:           48.37
2025-07-28 14:48:26   metrics/test.mAR:           63.33
2025-07-28 14:48:40 Epoch 171/200 (lr=1e-05), train loss 0.00159
2025-07-28 14:48:54 Epoch 172/200 (lr=1e-05), train loss 0.00114
2025-07-28 14:49:08 Epoch 173/200 (lr=1e-05), train loss 0.00139
2025-07-28 14:49:21 Epoch 174/200 (lr=1e-05), train loss 0.00130
2025-07-28 14:49:35 Epoch 175/200 (lr=1e-05), train loss 0.00099
2025-07-28 14:49:49 Epoch 176/200 (lr=1e-05), train loss 0.00146
2025-07-28 14:50:02 Epoch 177/200 (lr=1e-05), train loss 0.00111
2025-07-28 14:50:16 Epoch 178/200 (lr=1e-05), train loss 0.00099
2025-07-28 14:50:30 Epoch 179/200 (lr=1e-05), train loss 0.00156
2025-07-28 14:50:43 Training for epoch 180 done, starting evaluation
2025-07-28 14:50:49 Epoch 180/200 (lr=1e-05), train loss 0.00118, valid loss 0.00376
2025-07-28 14:50:49 Model performance:
2025-07-28 14:50:49   metrics/test.rmse:           4.23
2025-07-28 14:50:49   metrics/test.rmse_pcutoff:   2.67
2025-07-28 14:50:49   metrics/test.mAP:           48.37
2025-07-28 14:50:49   metrics/test.mAR:           63.33
2025-07-28 14:51:04 Epoch 181/200 (lr=1e-05), train loss 0.00103
2025-07-28 14:51:18 Epoch 182/200 (lr=1e-05), train loss 0.00116
2025-07-28 14:51:32 Epoch 183/200 (lr=1e-05), train loss 0.00115
2025-07-28 14:51:45 Epoch 184/200 (lr=1e-05), train loss 0.00101
2025-07-28 14:52:05 Epoch 185/200 (lr=1e-05), train loss 0.00132
2025-07-28 14:52:21 Epoch 186/200 (lr=1e-05), train loss 0.00111
2025-07-28 14:52:34 Epoch 187/200 (lr=1e-05), train loss 0.00157
2025-07-28 14:52:48 Epoch 188/200 (lr=1e-05), train loss 0.00110
2025-07-28 14:53:02 Epoch 189/200 (lr=1e-05), train loss 0.00150
2025-07-28 14:53:15 Training for epoch 190 done, starting evaluation
2025-07-28 14:53:21 Epoch 190/200 (lr=1e-05), train loss 0.00118, valid loss 0.00372
2025-07-28 14:53:21 Model performance:
2025-07-28 14:53:21   metrics/test.rmse:           4.27
2025-07-28 14:53:21   metrics/test.rmse_pcutoff:   2.70
2025-07-28 14:53:21   metrics/test.mAP:           48.37
2025-07-28 14:53:21   metrics/test.mAR:           63.33
2025-07-28 14:53:37 Epoch 191/200 (lr=1e-05), train loss 0.00181
2025-07-28 14:53:50 Epoch 192/200 (lr=1e-05), train loss 0.00115
2025-07-28 14:54:04 Epoch 193/200 (lr=1e-05), train loss 0.00143
2025-07-28 14:54:18 Epoch 194/200 (lr=1e-05), train loss 0.00130
2025-07-28 14:54:37 Epoch 195/200 (lr=1e-05), train loss 0.00126
2025-07-28 14:54:52 Epoch 196/200 (lr=1e-05), train loss 0.00139
2025-07-28 14:55:06 Epoch 197/200 (lr=1e-05), train loss 0.00123
2025-07-28 14:55:20 Epoch 198/200 (lr=1e-05), train loss 0.00107
2025-07-28 14:55:33 Epoch 199/200 (lr=1e-05), train loss 0.00127
2025-07-28 14:55:47 Training for epoch 200 done, starting evaluation
2025-07-28 14:55:53 Epoch 200/200 (lr=1e-05), train loss 0.00126, valid loss 0.00361
2025-07-28 14:55:53 Model performance:
2025-07-28 14:55:53   metrics/test.rmse:           4.28
2025-07-28 14:55:53   metrics/test.rmse_pcutoff:   2.84
2025-07-28 14:55:53   metrics/test.mAP:           48.37
2025-07-28 14:55:53   metrics/test.mAR:           63.33
